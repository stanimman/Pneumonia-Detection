{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stanimman/Pneumonia-Detection/blob/master/Mura_fast_ai_1_18_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egj2r-nUiwsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://fs2.transfernow.net/download/5db129db8745a/master/XR_ELBOW_v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUOWDobWwIYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip XR_ELBOW_v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZmRUQwe5bM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bgbclKvwrD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "path = Path('/content/XR_ELBOW_v1.1')\n",
        "#import PIL,os,mimetypes\n",
        "#Path.ls = lambda x: list(x.iterdir())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqbDsr1U6Nia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#path.ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51OrXWGj6Vua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(path/'valid'/'XR_ELBOW'/'patient11812'/'study1_positive').ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p6a-iLtiyxz",
        "colab_type": "code",
        "outputId": "9320b49a-12ae-478c-c907-00b06524d636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/fastai/course-v3"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 5200 (delta 28), reused 4 (delta 0), pack-reused 5140\u001b[K\n",
            "Receiving objects: 100% (5200/5200), 238.78 MiB | 30.56 MiB/s, done.\n",
            "Resolving deltas: 100% (2816/2816), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSBSvvLSnNUq",
        "colab_type": "code",
        "outputId": "debe2145-84f5-4742-a1a0-39b01cc6908c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls XR_ELBOW_v1.1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train  train_labeled_studies.csv  valid  valid_labeled_studies.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVmmwmsUozoh",
        "colab_type": "code",
        "outputId": "8c12914c-7c81-465a-f670-6881296568eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "course-v3  __MACOSX  sample_data  XR_ELBOW_v1.1  XR_ELBOW_v1.1.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOswzu2jplYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rm -r /content/exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhIkndJVolHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv -T course-v3/nbs/dl2/exp /content/exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bLsjta-znu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from exp.nb_05b import *\n",
        "torch.set_num_threads(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDdwzPMCBbHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Data Block API\n",
        "# A copy from Jermery's course on Data manipulation for Image\n",
        "\n",
        "import PIL,os,mimetypes\n",
        "Path.ls = lambda x: list(x.iterdir())\n",
        "\n",
        "class ListContainer():\n",
        "    def __init__(self, items): self.items = listify(items)\n",
        "    def __getitem__(self, idx):\n",
        "        try: return self.items[idx]\n",
        "        except TypeError:\n",
        "            if isinstance(idx[0],bool):\n",
        "                assert len(idx)==len(self) # bool mask\n",
        "                return [o for m,o in zip(idx,self.items) if m]\n",
        "            return [self.items[i] for i in idx]\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __iter__(self): return iter(self.items)\n",
        "    def __setitem__(self, i, o): self.items[i] = o\n",
        "    def __delitem__(self, i): del(self.items[i])\n",
        "    def __repr__(self):\n",
        "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
        "        if len(self)>10: res = res[:-1]+ '...]'\n",
        "        return res\n",
        "\n",
        "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))\n",
        "\n",
        "def setify(o): return o if isinstance(o,set) else set(listify(o))\n",
        "\n",
        "def _get_files(p, fs, extensions=None):\n",
        "    p = Path(p)\n",
        "    res = [p/f for f in fs if not f.startswith('.')\n",
        "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
        "    return res\n",
        "\n",
        "def get_files(path, extensions=None, recurse=False, include=None):\n",
        "    path = Path(path)\n",
        "    extensions = setify(extensions)\n",
        "    extensions = {e.lower() for e in extensions}\n",
        "    if recurse:\n",
        "        res = []\n",
        "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
        "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
        "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
        "            res += _get_files(p, f, extensions)\n",
        "        return res\n",
        "    else:\n",
        "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
        "        return _get_files(path, f, extensions)\n",
        "\n",
        "def compose(x, funcs, *args, order_key='_order', **kwargs):\n",
        "    key = lambda o: getattr(o, order_key, 0)\n",
        "    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)\n",
        "    return x\n",
        "\n",
        "class ItemList(ListContainer):\n",
        "    def __init__(self, items, path='.', tfms=None):\n",
        "        super().__init__(items)\n",
        "        self.path,self.tfms = Path(path),tfms\n",
        "\n",
        "    def __repr__(self): return f'{super().__repr__()}\\nPath: {self.path}'\n",
        "\n",
        "    def new(self, items, cls=None):\n",
        "        if cls is None: cls=self.__class__\n",
        "        return cls(items, self.path, tfms=self.tfms)\n",
        "\n",
        "    def  get(self, i): return i\n",
        "    def _get(self, i): return compose(self.get(i), self.tfms)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        res = super().__getitem__(idx)\n",
        "        if isinstance(res,list): return [self._get(o) for o in res]\n",
        "        return self._get(res)\n",
        "\n",
        "class ImageList(ItemList):\n",
        "    @classmethod\n",
        "    def from_files(cls, path, extensions=None, recurse=True, include=None, **kwargs):\n",
        "        if extensions is None: extensions = image_extensions\n",
        "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
        "\n",
        "    def get(self, fn): return PIL.Image.open(fn)\n",
        "\n",
        "class Transform(): _order=0\n",
        "\n",
        "class MakeRGB(Transform):\n",
        "    def __call__(self, item): return item.convert('RGB')\n",
        "\n",
        "def make_rgb(item): return item.convert('RGB')\n",
        "\n",
        "def grandparent_splitter(fn, valid_name='valid', train_name='train'):\n",
        "    gp = fn.parent.parent.name\n",
        "    return True if gp==valid_name else False if gp==train_name else None\n",
        "\n",
        "def split_by_func(items, f):\n",
        "    mask = [f(o) for o in items]\n",
        "    # `None` values will be filtered out\n",
        "    f = [o for o,m in zip(items,mask) if m==False]\n",
        "    t = [o for o,m in zip(items,mask) if m==True ]\n",
        "    return f,t\n",
        "\n",
        "class SplitData():\n",
        "    def __init__(self, train, valid): self.train,self.valid = train,valid\n",
        "\n",
        "    def __getattr__(self,k): return getattr(self.train,k)\n",
        "    #This is needed if we want to pickle SplitData and be able to load it back without recursion errors\n",
        "    def __setstate__(self,data:Any): self.__dict__.update(data)\n",
        "\n",
        "    @classmethod\n",
        "    def split_by_func(cls, il, f):\n",
        "        lists = map(il.new, split_by_func(il.items, f))\n",
        "        return cls(*lists)\n",
        "\n",
        "    def __repr__(self): return f'{self.__class__.__name__}\\nTrain: {self.train}\\nValid: {self.valid}\\n'\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "def uniqueify(x, sort=False):\n",
        "    res = list(OrderedDict.fromkeys(x).keys())\n",
        "    if sort: res.sort()\n",
        "    return res\n",
        "\n",
        "class Processor():\n",
        "    def process(self, items): return items\n",
        "\n",
        "class CategoryProcessor(Processor):\n",
        "    def __init__(self): self.vocab=None\n",
        "\n",
        "    def __call__(self, items):\n",
        "        #The vocab is defined on the first use.\n",
        "        if self.vocab is None:\n",
        "            self.vocab = uniqueify(items)\n",
        "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
        "        return [self.proc1(o) for o in items]\n",
        "    def proc1(self, item):  return self.otoi[item]\n",
        "\n",
        "    def deprocess(self, idxs):\n",
        "        assert self.vocab is not None\n",
        "        return [self.deproc1(idx) for idx in idxs]\n",
        "    def deproc1(self, idx): return self.vocab[idx]\n",
        "\n",
        "def parent_labeler(fn): return fn.parent.name\n",
        "\n",
        "def _label_by_func(ds, f, cls=ItemList): return cls([f(o) for o in ds.items], path=ds.path)\n",
        "\n",
        "#This is a slightly different from what was seen during the lesson,\n",
        "#   we'll discuss the changes in lesson 11\n",
        "class LabeledData():\n",
        "    def process(self, il, proc): return il.new(compose(il.items, proc))\n",
        "\n",
        "    def __init__(self, x, y, proc_x=None, proc_y=None):\n",
        "        self.x,self.y = self.process(x, proc_x),self.process(y, proc_y)\n",
        "        self.proc_x,self.proc_y = proc_x,proc_y\n",
        "\n",
        "    def __repr__(self): return f'{self.__class__.__name__}\\nx: {self.x}\\ny: {self.y}\\n'\n",
        "    def __getitem__(self,idx): return self.x[idx],self.y[idx]\n",
        "    def __len__(self): return len(self.x)\n",
        "\n",
        "    def x_obj(self, idx): return self.obj(self.x, idx, self.proc_x)\n",
        "    def y_obj(self, idx): return self.obj(self.y, idx, self.proc_y)\n",
        "\n",
        "    def obj(self, items, idx, procs):\n",
        "        isint = isinstance(idx, int) or (isinstance(idx,torch.LongTensor) and not idx.ndim)\n",
        "        item = items[idx]\n",
        "        for proc in reversed(listify(procs)):\n",
        "            item = proc.deproc1(item) if isint else proc.deprocess(item)\n",
        "        return item\n",
        "\n",
        "    @classmethod\n",
        "    def label_by_func(cls, il, f, proc_x=None, proc_y=None):\n",
        "        return cls(il, _label_by_func(il, f), proc_x=proc_x, proc_y=proc_y)\n",
        "\n",
        "def label_by_func(sd, f, proc_x=None, proc_y=None):\n",
        "    train = LabeledData.label_by_func(sd.train, f, proc_x=proc_x, proc_y=proc_y)\n",
        "    valid = LabeledData.label_by_func(sd.valid, f, proc_x=proc_x, proc_y=proc_y)\n",
        "    return SplitData(train,valid)\n",
        "\n",
        "class ResizeFixed(Transform):\n",
        "    _order=10\n",
        "    def __init__(self,size):\n",
        "        if isinstance(size,int): size=(size,size)\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, item): return item.resize(self.size, PIL.Image.BILINEAR)\n",
        "\n",
        "def to_byte_tensor(item):\n",
        "    res = torch.ByteTensor(torch.ByteStorage.from_buffer(item.tobytes()))\n",
        "    w,h = item.size\n",
        "    return res.view(h,w,-1).permute(2,0,1)\n",
        "to_byte_tensor._order=20\n",
        "\n",
        "def to_float_tensor(item): return item.float().div_(255.)\n",
        "to_float_tensor._order=30\n",
        "\n",
        "def show_image(im, figsize=(3,3)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(im.permute(1,2,0))\n",
        "\n",
        "class DataBunch():\n",
        "    def __init__(self, train_dl, valid_dl, c_in=None, c_out=None):\n",
        "        self.train_dl,self.valid_dl,self.c_in,self.c_out = train_dl,valid_dl,c_in,c_out\n",
        "\n",
        "    @property\n",
        "    def train_ds(self): return self.train_dl.dataset\n",
        "\n",
        "    @property\n",
        "    def valid_ds(self): return self.valid_dl.dataset\n",
        "\n",
        "def databunchify(sd, bs, c_in=None, c_out=None, **kwargs):\n",
        "    dls = get_dls(sd.train, sd.valid, bs, **kwargs)\n",
        "    return DataBunch(*dls, c_in=c_in, c_out=c_out)\n",
        "\n",
        "SplitData.to_databunch = databunchify\n",
        "\n",
        "def normalize_chan(x, mean, std):\n",
        "    return (x-mean[...,None,None]) / std[...,None,None]\n",
        "\n",
        "_m = tensor([0.47, 0.48, 0.45])\n",
        "_s = tensor([0.29, 0.28, 0.30])\n",
        "norm_imagenette = partial(normalize_chan, mean=_m.cuda(), std=_s.cuda())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEIPY7SlG0Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformation API\n",
        "\n",
        "#################################################\n",
        "### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n",
        "#################################################\n",
        "# file to edit: dev_nb/10_augmentation.ipynb\n",
        "\n",
        "from exp.nb_09c import *\n",
        "\n",
        "make_rgb._order=0\n",
        "\n",
        "import random\n",
        "\n",
        "def show_image(im, ax=None, figsize=(3,3)):\n",
        "    if ax is None: _,ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im.permute(1,2,0))\n",
        "\n",
        "def show_batch(x, c=4, r=None, figsize=None):\n",
        "    n = len(x)\n",
        "    if r is None: r = int(math.ceil(n/c))\n",
        "    if figsize is None: figsize=(c*3,r*3)\n",
        "    fig,axes = plt.subplots(r,c, figsize=figsize)\n",
        "    for xi,ax in zip(x,axes.flat): show_image(xi, ax)\n",
        "\n",
        "class PilTransform(Transform): _order=11\n",
        "\n",
        "class PilRandomFlip(PilTransform):\n",
        "    def __init__(self, p=0.5): self.p=p\n",
        "    def __call__(self, x):\n",
        "        return x.transpose(PIL.Image.FLIP_LEFT_RIGHT) if random.random()<self.p else x\n",
        "\n",
        "class PilRandomDihedral(PilTransform):\n",
        "    def __init__(self, p=0.75): self.p=p*7/8 #Little hack to get the 1/8 identity dihedral transform taken into account.\n",
        "    def __call__(self, x):\n",
        "        if random.random()>self.p: return x\n",
        "        return x.transpose(random.randint(0,6))\n",
        "\n",
        "from random import randint\n",
        "\n",
        "def process_sz(sz):\n",
        "    sz = listify(sz)\n",
        "    return tuple(sz if len(sz)==2 else [sz[0],sz[0]])\n",
        "\n",
        "def default_crop_size(w,h): return [w,w] if w < h else [h,h]\n",
        "\n",
        "class GeneralCrop(PilTransform):\n",
        "    def __init__(self, size, crop_size=None, resample=PIL.Image.BILINEAR):\n",
        "        self.resample,self.size = resample,process_sz(size)\n",
        "        self.crop_size = None if crop_size is None else process_sz(crop_size)\n",
        "\n",
        "    def default_crop_size(self, w,h): return default_crop_size(w,h)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        csize = self.default_crop_size(*x.size) if self.crop_size is None else self.crop_size\n",
        "        return x.transform(self.size, PIL.Image.EXTENT, self.get_corners(*x.size, *csize), resample=self.resample)\n",
        "\n",
        "    def get_corners(self, w, h): return (0,0,w,h)\n",
        "\n",
        "class CenterCrop(GeneralCrop):\n",
        "    def __init__(self, size, scale=1.14, resample=PIL.Image.BILINEAR):\n",
        "        super().__init__(size, resample=resample)\n",
        "        self.scale = scale\n",
        "\n",
        "    def default_crop_size(self, w,h): return [w/self.scale,h/self.scale]\n",
        "\n",
        "    def get_corners(self, w, h, wc, hc):\n",
        "        return ((w-wc)//2, (h-hc)//2, (w-wc)//2+wc, (h-hc)//2+hc)\n",
        "\n",
        "class RandomResizedCrop(GeneralCrop):\n",
        "    def __init__(self, size, scale=(0.08,1.0), ratio=(3./4., 4./3.), resample=PIL.Image.BILINEAR):\n",
        "        super().__init__(size, resample=resample)\n",
        "        self.scale,self.ratio = scale,ratio\n",
        "\n",
        "    def get_corners(self, w, h, wc, hc):\n",
        "        area = w*h\n",
        "        #Tries 10 times to get a proper crop inside the image.\n",
        "        for attempt in range(10):\n",
        "            area = random.uniform(*self.scale) * area\n",
        "            ratio = math.exp(random.uniform(math.log(self.ratio[0]), math.log(self.ratio[1])))\n",
        "            new_w = int(round(math.sqrt(area * ratio)))\n",
        "            new_h = int(round(math.sqrt(area / ratio)))\n",
        "            if new_w <= w and new_h <= h:\n",
        "                left = random.randint(0, w - new_w)\n",
        "                top  = random.randint(0, h - new_h)\n",
        "                return (left, top, left + new_w, top + new_h)\n",
        "\n",
        "        # Fallback to central crop\n",
        "        left,top = randint(0,w-self.crop_size[0]),randint(0,h-self.crop_size[1])\n",
        "        return (left, top, left+self.crop_size[0], top+self.crop_size[1])\n",
        "        # Fallback to central crop\n",
        "\n",
        "from torch import FloatTensor,LongTensor\n",
        "\n",
        "def find_coeffs(orig_pts, targ_pts):\n",
        "    matrix = []\n",
        "    #The equations we'll need to solve.\n",
        "    for p1, p2 in zip(targ_pts, orig_pts):\n",
        "        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n",
        "        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n",
        "\n",
        "    A = FloatTensor(matrix)\n",
        "    B = FloatTensor(orig_pts).view(8, 1)\n",
        "    #The 8 scalars we seek are solution of AX = B\n",
        "    return list(torch.solve(B,A)[0][:,0])\n",
        "\n",
        "def warp(img, size, src_coords, resample=PIL.Image.BILINEAR):\n",
        "    w,h = size\n",
        "    targ_coords = ((0,0),(0,h),(w,h),(w,0))\n",
        "    c = find_coeffs(src_coords,targ_coords)\n",
        "    res = img.transform(size, PIL.Image.PERSPECTIVE, list(c), resample=resample)\n",
        "    return res\n",
        "\n",
        "def uniform(a,b): return a + (b-a) * random.random()\n",
        "\n",
        "class PilTiltRandomCrop(PilTransform):\n",
        "    def __init__(self, size, crop_size=None, magnitude=0., resample=PIL.Image.BILINEAR):\n",
        "        self.resample,self.size,self.magnitude = resample,process_sz(size),magnitude\n",
        "        self.crop_size = None if crop_size is None else process_sz(crop_size)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        csize = default_crop_size(*x.size) if self.crop_size is None else self.crop_size\n",
        "        left,top = randint(0,x.size[0]-csize[0]),randint(0,x.size[1]-csize[1])\n",
        "        top_magn = min(self.magnitude, left/csize[0], (x.size[0]-left)/csize[0]-1)\n",
        "        lr_magn  = min(self.magnitude, top /csize[1], (x.size[1]-top) /csize[1]-1)\n",
        "        up_t,lr_t = uniform(-top_magn, top_magn),uniform(-lr_magn, lr_magn)\n",
        "        src_corners = tensor([[-up_t, -lr_t], [up_t, 1+lr_t], [1-up_t, 1-lr_t], [1+up_t, lr_t]])\n",
        "        src_corners = src_corners * tensor(csize).float() + tensor([left,top]).float()\n",
        "        src_corners = tuple([(int(o[0].item()), int(o[1].item())) for o in src_corners])\n",
        "        return warp(x, self.size, src_corners, resample=self.resample)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def np_to_float(x): return torch.from_numpy(np.array(x, dtype=np.float32, copy=False)).permute(2,0,1).contiguous()/255.\n",
        "np_to_float._order = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKmlLKL8CquF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = 128\n",
        "tfms = [make_rgb, RandomResizedCrop(size, scale=(0.35,1)), np_to_float, PilRandomFlip()]\n",
        "bs = 64\n",
        "il = ImageList.from_files(path, tfms=tfms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YShw9ghDFoxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changed the way the data Splitter is fetching the train / valid data split\n",
        "def parent_splitter(fn, valid_name='valid', train_name='train'):\n",
        "    gp = fn.parent.parent.parent.parent.name\n",
        "    return True if gp==valid_name else False if gp==train_name else None\n",
        "\n",
        "# Changed the way the data labeller is getting the label\n",
        "def parent_labeler(fn): return fn.parent.name.partition(\"_\")[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6YsY2xRFp0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sd = SplitData.split_by_func(il, partial(parent_splitter, valid_name='valid'))\n",
        "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1qGegTUxjuE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3118d0b-5569-4c8c-c5e6-744a3fc6cdde"
      },
      "source": [
        "set(ll.valid.y.items)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xao14D17HC7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll.valid.x.tfms = [make_rgb, CenterCrop(size), np_to_float]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgYAG9AiHM2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_1 = ll.to_databunch(bs, c_in=3, c_out=2, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqtmSKOf-zuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specific to MNIST\n",
        "#x_train,y_train,x_valid,y_valid = get_data()\n",
        "# def normalize_to(train, valid):\n",
        "#     m,s = train.mean(),train.std()\n",
        "#     return normalize(train, m, s), normalize(valid, m, s)\n",
        "  \n",
        "# x_train,x_valid = normalize_to(x_train,x_valid)\n",
        "# train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "# x_train.mean(),x_train.std()\n",
        "# nh,bs = 50,512\n",
        "# c = y_train.max().item()+1\n",
        "# loss_func = F.cross_entropy\n",
        "\n",
        "# data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)\n",
        "# def mnist_resize(x): return x.view(-1, 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4pqif18_Iv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x): return self.func(x)\n",
        "\n",
        "def flatten(x):      return x.view(x.shape[0], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4KVDlSB_YHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_model(data):\n",
        "    return nn.Sequential(\n",
        "        #Lambda(mnist_resize),\n",
        "        nn.Conv2d( 3, 8, 5, padding=2,stride=2), nn.ReLU(), #14\n",
        "        nn.Conv2d( 8,16, 3, padding=1,stride=2), nn.ReLU(), # 7\n",
        "        nn.Conv2d(16,32, 3, padding=1,stride=2), nn.ReLU(), # 4\n",
        "        nn.Conv2d(32,32, 3, padding=1,stride=2), nn.ReLU(), # 2\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        Lambda(flatten),\n",
        "        nn.Linear(32,data.c_out)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z03ZP5VD_YEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_cnn_model(data_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFO15mPX_YBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy\n",
        "cbfs = [partial(AvgStatsCallback,accuracy)]\n",
        "opt = optim.SGD(model.parameters(), lr=0.4)\n",
        "\n",
        "#run = Runner(cb_funcs=cbfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sweEHRUwPNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Learner():\n",
        "    def __init__(self, model, opt, loss_func, data):\n",
        "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw-IqEE6wGhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(model, opt, loss_func, data_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea-KFTxk_vIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, learn):\n",
        "    for epoch in range(epochs):\n",
        "        learn.model.train()\n",
        "        for xb,yb in learn.data.train_dl:\n",
        "            loss = learn.loss_func(learn.model(xb), yb)\n",
        "            loss.backward()\n",
        "            learn.opt.step()\n",
        "            learn.opt.zero_grad()\n",
        "\n",
        "        learn.model.eval()\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc = 0.,0.\n",
        "            for xb,yb in learn.data.valid_dl:\n",
        "                pred = learn.model(xb)\n",
        "                tot_loss += learn.loss_func(pred, yb)\n",
        "                tot_acc  += accuracy (pred,yb)\n",
        "        nv = len(learn.data.valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "    return tot_loss/nv, tot_acc/nv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9VbKuXNv7rz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dfa8f83-a070-4e6a-9a07-5a4cea82bbdf"
      },
      "source": [
        "loss,acc = fit(1, learn)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.7076) tensor(0.5168)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggprolen4JXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_batch(xb, yb, cb):\n",
        "    if not cb.begin_batch(xb,yb): return\n",
        "    loss = cb.learn.loss_func(cb.learn.model(xb), yb)\n",
        "    if not cb.after_loss(loss): return\n",
        "    loss.backward()\n",
        "    if cb.after_backward(): cb.learn.opt.step()\n",
        "    if cb.after_step(): cb.learn.opt.zero_grad()\n",
        "\n",
        "def all_batches(dl, cb):\n",
        "    for xb,yb in dl:\n",
        "        one_batch(xb, yb, cb)\n",
        "        if cb.do_stop(): return\n",
        "\n",
        "def fit(epochs, learn, cb):\n",
        "    if not cb.begin_fit(learn): return\n",
        "    for epoch in range(epochs):\n",
        "        if not cb.begin_epoch(epoch): continue\n",
        "        all_batches(learn.data.train_dl, cb)\n",
        "        \n",
        "        if cb.begin_validate():\n",
        "            with torch.no_grad(): all_batches(learn.data.valid_dl, cb)\n",
        "        if cb.do_stop() or not cb.after_epoch(): break\n",
        "    cb.after_fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2CxL0eg4NxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Callback():\n",
        "    def begin_fit(self, learn):\n",
        "        self.learn = learn\n",
        "        return True\n",
        "    def after_fit(self): return True\n",
        "    def begin_epoch(self, epoch):\n",
        "        self.epoch=epoch\n",
        "        return True\n",
        "    def begin_validate(self): return True\n",
        "    def after_epoch(self): return True\n",
        "    def begin_batch(self, xb, yb):\n",
        "        self.xb,self.yb = xb,yb\n",
        "        return True\n",
        "    def after_loss(self, loss):\n",
        "        self.loss = loss\n",
        "        return True\n",
        "    def after_backward(self): return True\n",
        "    def after_step(self): return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd_0fePX4T7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CallbackHandler():\n",
        "    def __init__(self,cbs=None):\n",
        "        self.cbs = cbs if cbs else []\n",
        "\n",
        "    def begin_fit(self, learn):\n",
        "        self.learn,self.in_train = learn,True\n",
        "        learn.stop = False\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_fit(learn)\n",
        "        return res\n",
        "\n",
        "    def after_fit(self):\n",
        "        res = not self.in_train\n",
        "        for cb in self.cbs: res = res and cb.after_fit()\n",
        "        return res\n",
        "    \n",
        "    def begin_epoch(self, epoch):\n",
        "        self.learn.model.train()\n",
        "        self.in_train=True\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
        "        return res\n",
        "\n",
        "    def begin_validate(self):\n",
        "        self.learn.model.eval()\n",
        "        self.in_train=False\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_validate()\n",
        "        return res\n",
        "\n",
        "    def after_epoch(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_epoch()\n",
        "        return res\n",
        "    \n",
        "    def begin_batch(self, xb, yb):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
        "        return res\n",
        "\n",
        "    def after_loss(self, loss):\n",
        "        res = self.in_train\n",
        "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
        "        return res\n",
        "\n",
        "    def after_backward(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_backward()\n",
        "        return res\n",
        "\n",
        "    def after_step(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_step()\n",
        "        return res\n",
        "    \n",
        "    def do_stop(self):\n",
        "        try:     return self.learn.stop\n",
        "        finally: self.learn.stop = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GquBSVMm4T-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(Callback):\n",
        "    def begin_fit(self,learn):\n",
        "        super().begin_fit(learn)\n",
        "        self.n_iters = 0\n",
        "        return True\n",
        "        \n",
        "    def after_step(self):\n",
        "        self.n_iters += 1\n",
        "        print(self.n_iters)\n",
        "        if self.n_iters>=10: self.learn.stop = True\n",
        "        return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yS7DTwy4UFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
        "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
        "def camel2snake(name):\n",
        "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
        "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
        "\n",
        "class Callback():\n",
        "    _order=0\n",
        "    def set_runner(self, run): self.run=run\n",
        "    def __getattr__(self, k): return getattr(self.run, k)\n",
        "    @property\n",
        "    def name(self):\n",
        "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
        "        return camel2snake(name or 'callback')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJbbl7iA4UDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainEvalCallback(Callback):\n",
        "    def begin_fit(self):\n",
        "        self.run.n_epochs=0.\n",
        "        self.run.n_iter=0\n",
        "    \n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.run.n_epochs += 1./self.iters\n",
        "        self.run.n_iter   += 1\n",
        "        \n",
        "    def begin_epoch(self):\n",
        "        self.run.n_epochs=self.epoch\n",
        "        self.model.train()\n",
        "        self.run.in_train=True\n",
        "\n",
        "    def begin_validate(self):\n",
        "        self.model.eval()\n",
        "        self.run.in_train=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfyPjseZ4UA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import *\n",
        "\n",
        "def listify(o):\n",
        "    if o is None: return []\n",
        "    if isinstance(o, list): return o\n",
        "    if isinstance(o, str): return [o]\n",
        "    if isinstance(o, Iterable): return list(o)\n",
        "    return [o]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jTSgu2F4nGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Runner():\n",
        "    def __init__(self, cbs=None, cb_funcs=None):\n",
        "        cbs = listify(cbs)\n",
        "        for cbf in listify(cb_funcs):\n",
        "            cb = cbf()\n",
        "            setattr(self, cb.name, cb)\n",
        "            cbs.append(cb)\n",
        "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
        "\n",
        "    @property\n",
        "    def opt(self):       return self.learn.opt\n",
        "    @property\n",
        "    def model(self):     return self.learn.model\n",
        "    @property\n",
        "    def loss_func(self): return self.learn.loss_func\n",
        "    @property\n",
        "    def data(self):      return self.learn.data\n",
        "\n",
        "    def one_batch(self, xb, yb):\n",
        "        self.xb,self.yb = xb,yb\n",
        "        if self('begin_batch'): return\n",
        "        self.pred = self.model(self.xb)\n",
        "        if self('after_pred'): return\n",
        "        self.loss = self.loss_func(self.pred, self.yb)\n",
        "        if self('after_loss') or not self.in_train: return\n",
        "        self.loss.backward()\n",
        "        if self('after_backward'): return\n",
        "        self.opt.step()\n",
        "        if self('after_step'): return\n",
        "        self.opt.zero_grad()\n",
        "\n",
        "    def all_batches(self, dl):\n",
        "        self.iters = len(dl)\n",
        "        for xb,yb in dl:\n",
        "            if self.stop: break\n",
        "            self.one_batch(xb, yb)\n",
        "            self('after_batch')\n",
        "        self.stop=False\n",
        "\n",
        "    def fit(self, epochs, learn):\n",
        "        self.epochs,self.learn = epochs,learn\n",
        "\n",
        "        try:\n",
        "            for cb in self.cbs: cb.set_runner(self)\n",
        "            if self('begin_fit'): return\n",
        "            for epoch in range(epochs):\n",
        "                self.epoch = epoch\n",
        "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
        "\n",
        "                with torch.no_grad(): \n",
        "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
        "                if self('after_epoch'): break\n",
        "            \n",
        "        finally:\n",
        "            self('after_fit')\n",
        "            self.learn = None\n",
        "\n",
        "    def __call__(self, cb_name):\n",
        "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
        "            f = getattr(cb, cb_name, None)\n",
        "            if f and f(): return True\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b130t0ko4nJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AvgStats():\n",
        "    def __init__(self, metrics, in_train): self.metrics,self.in_train = listify(metrics),in_train\n",
        "    \n",
        "    def reset(self):\n",
        "        self.tot_loss,self.count = 0.,0\n",
        "        self.tot_mets = [0.] * len(self.metrics)\n",
        "        \n",
        "    @property\n",
        "    def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
        "    @property\n",
        "    def avg_stats(self): return [o/self.count for o in self.all_stats]\n",
        "    \n",
        "    def __repr__(self):\n",
        "        if not self.count: return \"\"\n",
        "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
        "\n",
        "    def accumulate(self, run):\n",
        "        bn = run.xb.shape[0]\n",
        "        self.tot_loss += run.loss * bn\n",
        "        self.count += bn\n",
        "        for i,m in enumerate(self.metrics):\n",
        "            self.tot_mets[i] += m(run.pred, run.yb) * bn\n",
        "\n",
        "class AvgStatsCallback(Callback):\n",
        "    def __init__(self, metrics):\n",
        "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
        "        \n",
        "    def begin_epoch(self):\n",
        "        self.train_stats.reset()\n",
        "        self.valid_stats.reset()\n",
        "        \n",
        "    def after_loss(self):\n",
        "        stats = self.train_stats if self.in_train else self.valid_stats\n",
        "        with torch.no_grad(): stats.accumulate(self.run)\n",
        "    \n",
        "    def after_epoch(self):\n",
        "        print(self.train_stats)\n",
        "        print(self.valid_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ3OC5Fy1U3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats = AvgStatsCallback([accuracy])\n",
        "run = Runner(cbs=stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZitlvU-d3abr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "da26c641-d427-49db-e9ea-605218807761"
      },
      "source": [
        "run.fit(2, learn)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.6755977608180389, tensor(0.5932)]\n",
            "valid: [0.7397635511172715, tensor(0.5054)]\n",
            "train: [0.6754220449230632, tensor(0.5932)]\n",
            "valid: [0.6900796869749664, tensor(0.5376)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X2fy6ASOc5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_scheds(pcts, scheds):\n",
        "    assert sum(pcts) == 1.\n",
        "    pcts = tensor([0] + listify(pcts))\n",
        "    assert torch.all(pcts >= 0)\n",
        "    pcts = torch.cumsum(pcts, 0)\n",
        "    def _inner(pos):\n",
        "        idx = (pos >= pcts).nonzero().max()\n",
        "        actual_pos = (pos-pcts[idx]) / (pcts[idx+1]-pcts[idx])\n",
        "        return scheds[idx](actual_pos)\n",
        "    return _inner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwExrP04PA7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recorder(Callback):\n",
        "    def begin_fit(self): self.lrs,self.losses = [],[]\n",
        "\n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
        "        self.losses.append(self.loss.detach().cpu())        \n",
        "\n",
        "    def plot_lr  (self): plt.plot(self.lrs)\n",
        "    def plot_loss(self): plt.plot(self.losses)\n",
        "\n",
        "class ParamScheduler(Callback):\n",
        "    _order=1\n",
        "    def __init__(self, pname, sched_func): self.pname,self.sched_func = pname,sched_func\n",
        "\n",
        "    def set_param(self):\n",
        "        for pg in self.opt.param_groups:\n",
        "            pg[self.pname] = self.sched_func(self.n_epochs/self.epochs)\n",
        "            \n",
        "    def begin_batch(self): \n",
        "        if self.in_train: self.set_param()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibThPazQBdj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sched = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oleAybu95cQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbfs = [Recorder,\n",
        "        partial(AvgStatsCallback,accuracy),\n",
        "        partial(ParamScheduler, 'lr', sched)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PyCU1L57tMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run = Runner(cb_funcs=cbfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFRnwvc1CVbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "06a40a6d-fff1-4d0c-c47c-e8dfb699721b"
      },
      "source": [
        "run.fit(3, learn)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.6734883283848357, tensor(0.5920)]\n",
            "valid: [0.9096068023353494, tensor(0.5054)]\n",
            "train: [0.6690864199389069, tensor(0.5912)]\n",
            "valid: [0.7425318564138105, tensor(0.5054)]\n",
            "train: [0.6646903043246806, tensor(0.5926)]\n",
            "valid: [0.6911937426495296, tensor(0.5054)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZWIlgxnPfQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "67eb9706-0985-4b18-806a-371184e47c44"
      },
      "source": [
        "run.recorder.plot_lr()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKfTvOpzPfOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c4a5f7dd-3dd5-42ac-a78d-22e423041329"
      },
      "source": [
        "run.recorder.plot_loss()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVnDOdGbmTWcE72ZWcP9FwqSnhiSuwlWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p2mJJJtLDS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from exp.nb_10b import *\n",
        "size = 128\n",
        "tfms = [make_rgb, RandomResizedCrop(size, scale=(0.35,1)), np_to_float, PilRandomFlip()]\n",
        "bs = 64\n",
        "il = ImageList.from_files(path, tfms=tfms)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7HMxwDDVAUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parent_splitter(fn, valid_name='valid', train_name='train'):\n",
        "    gp = fn.parent.parent.parent.parent.name\n",
        "    return True if gp==valid_name else False if gp==train_name else None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu7cZyrzS8jO",
        "colab_type": "code",
        "outputId": "d87d9d92-8c04-48dd-c8cf-f68fef8854bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#img = il[0]; \n",
        "#img\n",
        "#il.items[0].parent.parent.parent.parent.name\n",
        "il[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 128, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm6NP69RRh_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sd = SplitData.split_by_func(il, partial(parent_splitter, valid_name='valid'))\n",
        "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR1y18jcRxcR",
        "colab_type": "code",
        "outputId": "45705825-7edf-408c-be9d-006ec37f1cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "ll.y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e92432c7d885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'll' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3rGltdWLDbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll.valid.x.tfms = [make_rgb, CenterCrop(size), np_to_float]\n",
        "data = ll.to_databunch(bs, c_in=3, c_out=2, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwNuwNnFLDZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noop(x): return x\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x): return x.view(x.size(0), -1)\n",
        "\n",
        "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
        "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
        "\n",
        "act_fn = nn.ReLU(inplace=True)\n",
        "\n",
        "def init_cnn(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn(l)\n",
        "\n",
        "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
        "    bn = nn.BatchNorm2d(nf)\n",
        "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
        "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
        "    if act: layers.append(act_fn)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, expansion, ni, nh, stride=1):\n",
        "        super().__init__()\n",
        "        nf,ni = nh*expansion,ni*expansion\n",
        "        layers  = [conv_layer(ni, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 3, zero_bn=True, act=False)\n",
        "        ] if expansion == 1 else [\n",
        "                   conv_layer(ni, nh, 1),\n",
        "                   conv_layer(nh, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 1, zero_bn=True, act=False)\n",
        "        ]\n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False)\n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "\n",
        "    def forward(self, x): return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
        "\n",
        "class XResNet(nn.Sequential):\n",
        "    @classmethod\n",
        "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
        "        nfs = [c_in, (c_in+1)*8, 64, 64]\n",
        "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
        "            for i in range(3)]\n",
        "\n",
        "        nfs = [64//expansion,64,128,256,512]\n",
        "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
        "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
        "                  for i,l in enumerate(layers)]\n",
        "        res = cls(\n",
        "            *stem,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            *res_layers,\n",
        "            nn.AdaptiveAvgPool2d(1), Flatten(),\n",
        "            nn.Linear(nfs[-1]*expansion, c_out),\n",
        "        )\n",
        "        init_cnn(res)\n",
        "        return res\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_layer(expansion, ni, nf, n_blocks, stride):\n",
        "        return nn.Sequential(\n",
        "            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
        "              for i in range(n_blocks)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHuqyIO-LDXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
        "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
        "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
        "def xresnet101(**kwargs): return XResNet.create(4, [3, 4, 23, 3], **kwargs)\n",
        "def xresnet152(**kwargs): return XResNet.create(4, [3, 8, 36, 3], **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngerQBaoW6o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbfs = [partial(AvgStatsCallback,accuracy), ProgressCallback, CudaCallback,\n",
        "        partial(BatchTransformXCallback, norm_imagenette),\n",
        "#         partial(MixUp, alpha=0.2)\n",
        "       ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yevGFz2ZXH7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = LabelSmoothingCrossEntropy()\n",
        "arch = partial(xresnet18, c_out=2)\n",
        "opt_func = adam_opt(mom=0.9, mom_sqr=0.99, eps=1e-6, wd=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP3EhfvnXMFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(dl, learn):\n",
        "    learn.xb,learn.yb = next(iter(dl))\n",
        "    learn.do_begin_fit(0)\n",
        "    learn('begin_batch')\n",
        "    learn('after_fit')\n",
        "    return learn.xb,learn.yb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDMdCyuKXMOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_summary(model, data, find_all=False, print_mod=False):\n",
        "    xb,yb = get_batch(data.valid_dl, learn)\n",
        "    mods = find_modules(model, is_lin_layer) if find_all else model.children()\n",
        "    f = lambda hook,mod,inp,out: print(f\"====\\n{mod}\\n\" if print_mod else \"\", out.shape)\n",
        "    with Hooks(mods, f) as hooks: learn.model(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI0kYVZnXUTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(arch(), data, loss_func, lr=1, cb_funcs=cbfs, opt_func=opt_func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czJ34bqmXdU4",
        "colab_type": "code",
        "outputId": "bef81a38-152d-428c-ac13-4d6f1be87cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "#learn.model = learn.model.cuda()\n",
        "model_summary(learn.model, data, print_mod=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-43901f8e6f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_mod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_summary' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isjmscE9XdR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arch = partial(xresnet34, c_out=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHj_dw80Xtc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(arch(), data, loss_func, lr=1, cb_funcs=cbfs, opt_func=opt_func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMSTtKDgXtjX",
        "colab_type": "code",
        "outputId": "a5cd633b-9ce2-40d8-bde9-8c884ce2f17d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.fit(1, cbs=[LR_Find(), Recorder()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>valid_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, xb, yb)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcb_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_CBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_05b.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09c.py\u001b[0m in \u001b[0;36mafter_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stats\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_train\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_04.py\u001b[0m in \u001b[0;36maccumulate\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtot_mets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_03.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(out, yb)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /pytorch/aten/src/THC/THCTensorMathReduce.cuh:517",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-db4bd680ce9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLR_Find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, cbs, reset_opt)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_begin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, xb, yb)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m:\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcb_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_CBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_05b.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09.py\u001b[0m in \u001b[0;36mafter_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot_lr\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    }
  ]
}