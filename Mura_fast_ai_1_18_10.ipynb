{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stanimman/Pneumonia-Detection/blob/master/Mura_fast_ai_1_18_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egj2r-nUiwsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://fs2.transfernow.net/download/5db129db8745a/master/XR_ELBOW_v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUOWDobWwIYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip XR_ELBOW_v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZmRUQwe5bM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bgbclKvwrD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "path = Path('/content/XR_ELBOW_v1.1')\n",
        "#import PIL,os,mimetypes\n",
        "#Path.ls = lambda x: list(x.iterdir())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqbDsr1U6Nia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#path.ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51OrXWGj6Vua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(path/'valid'/'XR_ELBOW'/'patient11812'/'study1_positive').ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p6a-iLtiyxz",
        "colab_type": "code",
        "outputId": "9320b49a-12ae-478c-c907-00b06524d636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/fastai/course-v3"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 5200 (delta 28), reused 4 (delta 0), pack-reused 5140\u001b[K\n",
            "Receiving objects: 100% (5200/5200), 238.78 MiB | 30.56 MiB/s, done.\n",
            "Resolving deltas: 100% (2816/2816), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSBSvvLSnNUq",
        "colab_type": "code",
        "outputId": "debe2145-84f5-4742-a1a0-39b01cc6908c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls XR_ELBOW_v1.1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train  train_labeled_studies.csv  valid  valid_labeled_studies.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVmmwmsUozoh",
        "colab_type": "code",
        "outputId": "8c12914c-7c81-465a-f670-6881296568eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "course-v3  __MACOSX  sample_data  XR_ELBOW_v1.1  XR_ELBOW_v1.1.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOswzu2jplYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rm -r /content/exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhIkndJVolHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv -T course-v3/nbs/dl2/exp /content/exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bLsjta-znu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from exp.nb_05b import *\n",
        "torch.set_num_threads(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDdwzPMCBbHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Data Block API\n",
        "# A copy from Jermery's course on Data manipulation for Image\n",
        "\n",
        "import PIL,os,mimetypes\n",
        "Path.ls = lambda x: list(x.iterdir())\n",
        "\n",
        "class ListContainer():\n",
        "    def __init__(self, items): self.items = listify(items)\n",
        "    def __getitem__(self, idx):\n",
        "        try: return self.items[idx]\n",
        "        except TypeError:\n",
        "            if isinstance(idx[0],bool):\n",
        "                assert len(idx)==len(self) # bool mask\n",
        "                return [o for m,o in zip(idx,self.items) if m]\n",
        "            return [self.items[i] for i in idx]\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __iter__(self): return iter(self.items)\n",
        "    def __setitem__(self, i, o): self.items[i] = o\n",
        "    def __delitem__(self, i): del(self.items[i])\n",
        "    def __repr__(self):\n",
        "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
        "        if len(self)>10: res = res[:-1]+ '...]'\n",
        "        return res\n",
        "\n",
        "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))\n",
        "\n",
        "def setify(o): return o if isinstance(o,set) else set(listify(o))\n",
        "\n",
        "def _get_files(p, fs, extensions=None):\n",
        "    p = Path(p)\n",
        "    res = [p/f for f in fs if not f.startswith('.')\n",
        "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
        "    return res\n",
        "\n",
        "def get_files(path, extensions=None, recurse=False, include=None):\n",
        "    path = Path(path)\n",
        "    extensions = setify(extensions)\n",
        "    extensions = {e.lower() for e in extensions}\n",
        "    if recurse:\n",
        "        res = []\n",
        "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
        "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
        "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
        "            res += _get_files(p, f, extensions)\n",
        "        return res\n",
        "    else:\n",
        "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
        "        return _get_files(path, f, extensions)\n",
        "\n",
        "def compose(x, funcs, *args, order_key='_order', **kwargs):\n",
        "    key = lambda o: getattr(o, order_key, 0)\n",
        "    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)\n",
        "    return x\n",
        "\n",
        "class ItemList(ListContainer):\n",
        "    def __init__(self, items, path='.', tfms=None):\n",
        "        super().__init__(items)\n",
        "        self.path,self.tfms = Path(path),tfms\n",
        "\n",
        "    def __repr__(self): return f'{super().__repr__()}\\nPath: {self.path}'\n",
        "\n",
        "    def new(self, items, cls=None):\n",
        "        if cls is None: cls=self.__class__\n",
        "        return cls(items, self.path, tfms=self.tfms)\n",
        "\n",
        "    def  get(self, i): return i\n",
        "    def _get(self, i): return compose(self.get(i), self.tfms)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        res = super().__getitem__(idx)\n",
        "        if isinstance(res,list): return [self._get(o) for o in res]\n",
        "        return self._get(res)\n",
        "\n",
        "class ImageList(ItemList):\n",
        "    @classmethod\n",
        "    def from_files(cls, path, extensions=None, recurse=True, include=None, **kwargs):\n",
        "        if extensions is None: extensions = image_extensions\n",
        "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
        "\n",
        "    def get(self, fn): return PIL.Image.open(fn)\n",
        "\n",
        "class Transform(): _order=0\n",
        "\n",
        "class MakeRGB(Transform):\n",
        "    def __call__(self, item): return item.convert('RGB')\n",
        "\n",
        "def make_rgb(item): return item.convert('RGB')\n",
        "\n",
        "def grandparent_splitter(fn, valid_name='valid', train_name='train'):\n",
        "    gp = fn.parent.parent.name\n",
        "    return True if gp==valid_name else False if gp==train_name else None\n",
        "\n",
        "def split_by_func(items, f):\n",
        "    mask = [f(o) for o in items]\n",
        "    # `None` values will be filtered out\n",
        "    f = [o for o,m in zip(items,mask) if m==False]\n",
        "    t = [o for o,m in zip(items,mask) if m==True ]\n",
        "    return f,t\n",
        "\n",
        "class SplitData():\n",
        "    def __init__(self, train, valid): self.train,self.valid = train,valid\n",
        "\n",
        "    def __getattr__(self,k): return getattr(self.train,k)\n",
        "    #This is needed if we want to pickle SplitData and be able to load it back without recursion errors\n",
        "    def __setstate__(self,data:Any): self.__dict__.update(data)\n",
        "\n",
        "    @classmethod\n",
        "    def split_by_func(cls, il, f):\n",
        "        lists = map(il.new, split_by_func(il.items, f))\n",
        "        return cls(*lists)\n",
        "\n",
        "    def __repr__(self): return f'{self.__class__.__name__}\\nTrain: {self.train}\\nValid: {self.valid}\\n'\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "def uniqueify(x, sort=False):\n",
        "    res = list(OrderedDict.fromkeys(x).keys())\n",
        "    if sort: res.sort()\n",
        "    return res\n",
        "\n",
        "class Processor():\n",
        "    def process(self, items): return items\n",
        "\n",
        "class CategoryProcessor(Processor):\n",
        "    def __init__(self): self.vocab=None\n",
        "\n",
        "    def __call__(self, items):\n",
        "        #The vocab is defined on the first use.\n",
        "        if self.vocab is None:\n",
        "            self.vocab = uniqueify(items)\n",
        "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
        "        return [self.proc1(o) for o in items]\n",
        "    def proc1(self, item):  return self.otoi[item]\n",
        "\n",
        "    def deprocess(self, idxs):\n",
        "        assert self.vocab is not None\n",
        "        return [self.deproc1(idx) for idx in idxs]\n",
        "    def deproc1(self, idx): return self.vocab[idx]\n",
        "\n",
        "def parent_labeler(fn): return fn.parent.name\n",
        "\n",
        "def _label_by_func(ds, f, cls=ItemList): return cls([f(o) for o in ds.items], path=ds.path)\n",
        "\n",
        "#This is a slightly different from what was seen during the lesson,\n",
        "#   we'll discuss the changes in lesson 11\n",
        "class LabeledData():\n",
        "    def process(self, il, proc): return il.new(compose(il.items, proc))\n",
        "\n",
        "    def __init__(self, x, y, proc_x=None, proc_y=None):\n",
        "        self.x,self.y = self.process(x, proc_x),self.process(y, proc_y)\n",
        "        self.proc_x,self.proc_y = proc_x,proc_y\n",
        "\n",
        "    def __repr__(self): return f'{self.__class__.__name__}\\nx: {self.x}\\ny: {self.y}\\n'\n",
        "    def __getitem__(self,idx): return self.x[idx],self.y[idx]\n",
        "    def __len__(self): return len(self.x)\n",
        "\n",
        "    def x_obj(self, idx): return self.obj(self.x, idx, self.proc_x)\n",
        "    def y_obj(self, idx): return self.obj(self.y, idx, self.proc_y)\n",
        "\n",
        "    def obj(self, items, idx, procs):\n",
        "        isint = isinstance(idx, int) or (isinstance(idx,torch.LongTensor) and not idx.ndim)\n",
        "        item = items[idx]\n",
        "        for proc in reversed(listify(procs)):\n",
        "            item = proc.deproc1(item) if isint else proc.deprocess(item)\n",
        "        return item\n",
        "\n",
        "    @classmethod\n",
        "    def label_by_func(cls, il, f, proc_x=None, proc_y=None):\n",
        "        return cls(il, _label_by_func(il, f), proc_x=proc_x, proc_y=proc_y)\n",
        "\n",
        "def label_by_func(sd, f, proc_x=None, proc_y=None):\n",
        "    train = LabeledData.label_by_func(sd.train, f, proc_x=proc_x, proc_y=proc_y)\n",
        "    valid = LabeledData.label_by_func(sd.valid, f, proc_x=proc_x, proc_y=proc_y)\n",
        "    return SplitData(train,valid)\n",
        "\n",
        "class ResizeFixed(Transform):\n",
        "    _order=10\n",
        "    def __init__(self,size):\n",
        "        if isinstance(size,int): size=(size,size)\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, item): return item.resize(self.size, PIL.Image.BILINEAR)\n",
        "\n",
        "def to_byte_tensor(item):\n",
        "    res = torch.ByteTensor(torch.ByteStorage.from_buffer(item.tobytes()))\n",
        "    w,h = item.size\n",
        "    return res.view(h,w,-1).permute(2,0,1)\n",
        "to_byte_tensor._order=20\n",
        "\n",
        "def to_float_tensor(item): return item.float().div_(255.)\n",
        "to_float_tensor._order=30\n",
        "\n",
        "def show_image(im, figsize=(3,3)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(im.permute(1,2,0))\n",
        "\n",
        "class DataBunch():\n",
        "    def __init__(self, train_dl, valid_dl, c_in=None, c_out=None):\n",
        "        self.train_dl,self.valid_dl,self.c_in,self.c_out = train_dl,valid_dl,c_in,c_out\n",
        "\n",
        "    @property\n",
        "    def train_ds(self): return self.train_dl.dataset\n",
        "\n",
        "    @property\n",
        "    def valid_ds(self): return self.valid_dl.dataset\n",
        "\n",
        "def databunchify(sd, bs, c_in=None, c_out=None, **kwargs):\n",
        "    dls = get_dls(sd.train, sd.valid, bs, **kwargs)\n",
        "    return DataBunch(*dls, c_in=c_in, c_out=c_out)\n",
        "\n",
        "SplitData.to_databunch = databunchify\n",
        "\n",
        "def normalize_chan(x, mean, std):\n",
        "    return (x-mean[...,None,None]) / std[...,None,None]\n",
        "\n",
        "_m = tensor([0.47, 0.48, 0.45])\n",
        "_s = tensor([0.29, 0.28, 0.30])\n",
        "norm_imagenette = partial(normalize_chan, mean=_m.cuda(), std=_s.cuda())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEIPY7SlG0Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformation API\n",
        "\n",
        "#################################################\n",
        "### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n",
        "#################################################\n",
        "# file to edit: dev_nb/10_augmentation.ipynb\n",
        "\n",
        "from exp.nb_09c import *\n",
        "\n",
        "make_rgb._order=0\n",
        "\n",
        "import random\n",
        "\n",
        "def show_image(im, ax=None, figsize=(3,3)):\n",
        "    if ax is None: _,ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im.permute(1,2,0))\n",
        "\n",
        "def show_batch(x, c=4, r=None, figsize=None):\n",
        "    n = len(x)\n",
        "    if r is None: r = int(math.ceil(n/c))\n",
        "    if figsize is None: figsize=(c*3,r*3)\n",
        "    fig,axes = plt.subplots(r,c, figsize=figsize)\n",
        "    for xi,ax in zip(x,axes.flat): show_image(xi, ax)\n",
        "\n",
        "class PilTransform(Transform): _order=11\n",
        "\n",
        "class PilRandomFlip(PilTransform):\n",
        "    def __init__(self, p=0.5): self.p=p\n",
        "    def __call__(self, x):\n",
        "        return x.transpose(PIL.Image.FLIP_LEFT_RIGHT) if random.random()<self.p else x\n",
        "\n",
        "class PilRandomDihedral(PilTransform):\n",
        "    def __init__(self, p=0.75): self.p=p*7/8 #Little hack to get the 1/8 identity dihedral transform taken into account.\n",
        "    def __call__(self, x):\n",
        "        if random.random()>self.p: return x\n",
        "        return x.transpose(random.randint(0,6))\n",
        "\n",
        "from random import randint\n",
        "\n",
        "def process_sz(sz):\n",
        "    sz = listify(sz)\n",
        "    return tuple(sz if len(sz)==2 else [sz[0],sz[0]])\n",
        "\n",
        "def default_crop_size(w,h): return [w,w] if w < h else [h,h]\n",
        "\n",
        "class GeneralCrop(PilTransform):\n",
        "    def __init__(self, size, crop_size=None, resample=PIL.Image.BILINEAR):\n",
        "        self.resample,self.size = resample,process_sz(size)\n",
        "        self.crop_size = None if crop_size is None else process_sz(crop_size)\n",
        "\n",
        "    def default_crop_size(self, w,h): return default_crop_size(w,h)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        csize = self.default_crop_size(*x.size) if self.crop_size is None else self.crop_size\n",
        "        return x.transform(self.size, PIL.Image.EXTENT, self.get_corners(*x.size, *csize), resample=self.resample)\n",
        "\n",
        "    def get_corners(self, w, h): return (0,0,w,h)\n",
        "\n",
        "class CenterCrop(GeneralCrop):\n",
        "    def __init__(self, size, scale=1.14, resample=PIL.Image.BILINEAR):\n",
        "        super().__init__(size, resample=resample)\n",
        "        self.scale = scale\n",
        "\n",
        "    def default_crop_size(self, w,h): return [w/self.scale,h/self.scale]\n",
        "\n",
        "    def get_corners(self, w, h, wc, hc):\n",
        "        return ((w-wc)//2, (h-hc)//2, (w-wc)//2+wc, (h-hc)//2+hc)\n",
        "\n",
        "class RandomResizedCrop(GeneralCrop):\n",
        "    def __init__(self, size, scale=(0.08,1.0), ratio=(3./4., 4./3.), resample=PIL.Image.BILINEAR):\n",
        "        super().__init__(size, resample=resample)\n",
        "        self.scale,self.ratio = scale,ratio\n",
        "\n",
        "    def get_corners(self, w, h, wc, hc):\n",
        "        area = w*h\n",
        "        #Tries 10 times to get a proper crop inside the image.\n",
        "        for attempt in range(10):\n",
        "            area = random.uniform(*self.scale) * area\n",
        "            ratio = math.exp(random.uniform(math.log(self.ratio[0]), math.log(self.ratio[1])))\n",
        "            new_w = int(round(math.sqrt(area * ratio)))\n",
        "            new_h = int(round(math.sqrt(area / ratio)))\n",
        "            if new_w <= w and new_h <= h:\n",
        "                left = random.randint(0, w - new_w)\n",
        "                top  = random.randint(0, h - new_h)\n",
        "                return (left, top, left + new_w, top + new_h)\n",
        "\n",
        "        # Fallback to central crop\n",
        "        left,top = randint(0,w-self.crop_size[0]),randint(0,h-self.crop_size[1])\n",
        "        return (left, top, left+self.crop_size[0], top+self.crop_size[1])\n",
        "        # Fallback to central crop\n",
        "\n",
        "from torch import FloatTensor,LongTensor\n",
        "\n",
        "def find_coeffs(orig_pts, targ_pts):\n",
        "    matrix = []\n",
        "    #The equations we'll need to solve.\n",
        "    for p1, p2 in zip(targ_pts, orig_pts):\n",
        "        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n",
        "        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n",
        "\n",
        "    A = FloatTensor(matrix)\n",
        "    B = FloatTensor(orig_pts).view(8, 1)\n",
        "    #The 8 scalars we seek are solution of AX = B\n",
        "    return list(torch.solve(B,A)[0][:,0])\n",
        "\n",
        "def warp(img, size, src_coords, resample=PIL.Image.BILINEAR):\n",
        "    w,h = size\n",
        "    targ_coords = ((0,0),(0,h),(w,h),(w,0))\n",
        "    c = find_coeffs(src_coords,targ_coords)\n",
        "    res = img.transform(size, PIL.Image.PERSPECTIVE, list(c), resample=resample)\n",
        "    return res\n",
        "\n",
        "def uniform(a,b): return a + (b-a) * random.random()\n",
        "\n",
        "class PilTiltRandomCrop(PilTransform):\n",
        "    def __init__(self, size, crop_size=None, magnitude=0., resample=PIL.Image.BILINEAR):\n",
        "        self.resample,self.size,self.magnitude = resample,process_sz(size),magnitude\n",
        "        self.crop_size = None if crop_size is None else process_sz(crop_size)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        csize = default_crop_size(*x.size) if self.crop_size is None else self.crop_size\n",
        "        left,top = randint(0,x.size[0]-csize[0]),randint(0,x.size[1]-csize[1])\n",
        "        top_magn = min(self.magnitude, left/csize[0], (x.size[0]-left)/csize[0]-1)\n",
        "        lr_magn  = min(self.magnitude, top /csize[1], (x.size[1]-top) /csize[1]-1)\n",
        "        up_t,lr_t = uniform(-top_magn, top_magn),uniform(-lr_magn, lr_magn)\n",
        "        src_corners = tensor([[-up_t, -lr_t], [up_t, 1+lr_t], [1-up_t, 1-lr_t], [1+up_t, lr_t]])\n",
        "        src_corners = src_corners * tensor(csize).float() + tensor([left,top]).float()\n",
        "        src_corners = tuple([(int(o[0].item()), int(o[1].item())) for o in src_corners])\n",
        "        return warp(x, self.size, src_corners, resample=self.resample)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def np_to_float(x): return torch.from_numpy(np.array(x, dtype=np.float32, copy=False)).permute(2,0,1).contiguous()/255.\n",
        "np_to_float._order = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKmlLKL8CquF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = 128\n",
        "tfms = [make_rgb, RandomResizedCrop(size, scale=(0.35,1)), np_to_float, PilRandomFlip()]\n",
        "bs = 64\n",
        "il = ImageList.from_files(path, tfms=tfms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YShw9ghDFoxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changed the way the data Splitter is fetching the train / valid data split\n",
        "def parent_splitter(fn, valid_name='valid', train_name='train'):\n",
        "    gp = fn.parent.parent.parent.parent.name\n",
        "    return True if gp==valid_name else False if gp==train_name else None\n",
        "\n",
        "# Changed the way the data labeller is getting the label\n",
        "def parent_labeler(fn): return fn.parent.name.partition(\"_\")[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6YsY2xRFp0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sd = SplitData.split_by_func(il, partial(parent_splitter, valid_name='valid'))\n",
        "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1qGegTUxjuE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3118d0b-5569-4c8c-c5e6-744a3fc6cdde"
      },
      "source": [
        "set(ll.valid.y.items)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xao14D17HC7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll.valid.x.tfms = [make_rgb, CenterCrop(size), np_to_float]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgYAG9AiHM2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_1 = ll.to_databunch(bs, c_in=3, c_out=2, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqtmSKOf-zuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specific to MNIST\n",
        "#x_train,y_train,x_valid,y_valid = get_data()\n",
        "# def normalize_to(train, valid):\n",
        "#     m,s = train.mean(),train.std()\n",
        "#     return normalize(train, m, s), normalize(valid, m, s)\n",
        "  \n",
        "# x_train,x_valid = normalize_to(x_train,x_valid)\n",
        "# train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "# x_train.mean(),x_train.std()\n",
        "# nh,bs = 50,512\n",
        "# c = y_train.max().item()+1\n",
        "# loss_func = F.cross_entropy\n",
        "\n",
        "# data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)\n",
        "# def mnist_resize(x): return x.view(-1, 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4pqif18_Iv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x): return self.func(x)\n",
        "\n",
        "def flatten(x):      return x.view(x.shape[0], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4KVDlSB_YHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_model(data):\n",
        "    return nn.Sequential(\n",
        "        #Lambda(mnist_resize),\n",
        "        nn.Conv2d( 3, 8, 5, padding=2,stride=2), nn.ReLU(), #14\n",
        "        nn.Conv2d( 8,16, 3, padding=1,stride=2), nn.ReLU(), # 7\n",
        "        nn.Conv2d(16,32, 3, padding=1,stride=2), nn.ReLU(), # 4\n",
        "        nn.Conv2d(32,32, 3, padding=1,stride=2), nn.ReLU(), # 2\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        Lambda(flatten),\n",
        "        nn.Linear(32,data.c_out)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z03ZP5VD_YEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_cnn_model(data_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFO15mPX_YBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy\n",
        "cbfs = [partial(AvgStatsCallback,accuracy)]\n",
        "opt = optim.SGD(model.parameters(), lr=0.4)\n",
        "\n",
        "#run = Runner(cb_funcs=cbfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sweEHRUwPNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Learner():\n",
        "    def __init__(self, model, opt, loss_func, data):\n",
        "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw-IqEE6wGhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(model, opt, loss_func, data_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea-KFTxk_vIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, learn):\n",
        "    for epoch in range(epochs):\n",
        "        learn.model.train()\n",
        "        for xb,yb in learn.data.train_dl:\n",
        "            loss = learn.loss_func(learn.model(xb), yb)\n",
        "            loss.backward()\n",
        "            learn.opt.step()\n",
        "            learn.opt.zero_grad()\n",
        "\n",
        "        learn.model.eval()\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc = 0.,0.\n",
        "            for xb,yb in learn.data.valid_dl:\n",
        "                pred = learn.model(xb)\n",
        "                tot_loss += learn.loss_func(pred, yb)\n",
        "                tot_acc  += accuracy (pred,yb)\n",
        "        nv = len(learn.data.valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "    return tot_loss/nv, tot_acc/nv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9VbKuXNv7rz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dfa8f83-a070-4e6a-9a07-5a4cea82bbdf"
      },
      "source": [
        "loss,acc = fit(1, learn)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.7076) tensor(0.5168)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ3OC5Fy1U3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p2mJJJtLDS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from exp.nb_10b import *\n",
        "size = 128\n",
        "tfms = [make_rgb, RandomResizedCrop(size, scale=(0.35,1)), np_to_float, PilRandomFlip()]\n",
        "bs = 64\n",
        "il = ImageList.from_files(path, tfms=tfms)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7HMxwDDVAUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parent_splitter(fn, valid_name='valid', train_name='train'):\n",
        "    gp = fn.parent.parent.parent.parent.name\n",
        "    return True if gp==valid_name else False if gp==train_name else None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu7cZyrzS8jO",
        "colab_type": "code",
        "outputId": "d87d9d92-8c04-48dd-c8cf-f68fef8854bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#img = il[0]; \n",
        "#img\n",
        "#il.items[0].parent.parent.parent.parent.name\n",
        "il[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 128, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm6NP69RRh_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sd = SplitData.split_by_func(il, partial(parent_splitter, valid_name='valid'))\n",
        "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR1y18jcRxcR",
        "colab_type": "code",
        "outputId": "45705825-7edf-408c-be9d-006ec37f1cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "ll.y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e92432c7d885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'll' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3rGltdWLDbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll.valid.x.tfms = [make_rgb, CenterCrop(size), np_to_float]\n",
        "data = ll.to_databunch(bs, c_in=3, c_out=2, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwNuwNnFLDZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noop(x): return x\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x): return x.view(x.size(0), -1)\n",
        "\n",
        "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
        "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
        "\n",
        "act_fn = nn.ReLU(inplace=True)\n",
        "\n",
        "def init_cnn(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn(l)\n",
        "\n",
        "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
        "    bn = nn.BatchNorm2d(nf)\n",
        "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
        "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
        "    if act: layers.append(act_fn)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, expansion, ni, nh, stride=1):\n",
        "        super().__init__()\n",
        "        nf,ni = nh*expansion,ni*expansion\n",
        "        layers  = [conv_layer(ni, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 3, zero_bn=True, act=False)\n",
        "        ] if expansion == 1 else [\n",
        "                   conv_layer(ni, nh, 1),\n",
        "                   conv_layer(nh, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 1, zero_bn=True, act=False)\n",
        "        ]\n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False)\n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "\n",
        "    def forward(self, x): return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
        "\n",
        "class XResNet(nn.Sequential):\n",
        "    @classmethod\n",
        "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
        "        nfs = [c_in, (c_in+1)*8, 64, 64]\n",
        "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
        "            for i in range(3)]\n",
        "\n",
        "        nfs = [64//expansion,64,128,256,512]\n",
        "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
        "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
        "                  for i,l in enumerate(layers)]\n",
        "        res = cls(\n",
        "            *stem,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            *res_layers,\n",
        "            nn.AdaptiveAvgPool2d(1), Flatten(),\n",
        "            nn.Linear(nfs[-1]*expansion, c_out),\n",
        "        )\n",
        "        init_cnn(res)\n",
        "        return res\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_layer(expansion, ni, nf, n_blocks, stride):\n",
        "        return nn.Sequential(\n",
        "            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
        "              for i in range(n_blocks)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHuqyIO-LDXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
        "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
        "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
        "def xresnet101(**kwargs): return XResNet.create(4, [3, 4, 23, 3], **kwargs)\n",
        "def xresnet152(**kwargs): return XResNet.create(4, [3, 8, 36, 3], **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngerQBaoW6o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbfs = [partial(AvgStatsCallback,accuracy), ProgressCallback, CudaCallback,\n",
        "        partial(BatchTransformXCallback, norm_imagenette),\n",
        "#         partial(MixUp, alpha=0.2)\n",
        "       ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yevGFz2ZXH7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = LabelSmoothingCrossEntropy()\n",
        "arch = partial(xresnet18, c_out=2)\n",
        "opt_func = adam_opt(mom=0.9, mom_sqr=0.99, eps=1e-6, wd=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP3EhfvnXMFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(dl, learn):\n",
        "    learn.xb,learn.yb = next(iter(dl))\n",
        "    learn.do_begin_fit(0)\n",
        "    learn('begin_batch')\n",
        "    learn('after_fit')\n",
        "    return learn.xb,learn.yb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDMdCyuKXMOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_summary(model, data, find_all=False, print_mod=False):\n",
        "    xb,yb = get_batch(data.valid_dl, learn)\n",
        "    mods = find_modules(model, is_lin_layer) if find_all else model.children()\n",
        "    f = lambda hook,mod,inp,out: print(f\"====\\n{mod}\\n\" if print_mod else \"\", out.shape)\n",
        "    with Hooks(mods, f) as hooks: learn.model(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI0kYVZnXUTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(arch(), data, loss_func, lr=1, cb_funcs=cbfs, opt_func=opt_func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czJ34bqmXdU4",
        "colab_type": "code",
        "outputId": "bef81a38-152d-428c-ac13-4d6f1be87cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "#learn.model = learn.model.cuda()\n",
        "model_summary(learn.model, data, print_mod=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-43901f8e6f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_mod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_summary' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isjmscE9XdR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arch = partial(xresnet34, c_out=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHj_dw80Xtc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(arch(), data, loss_func, lr=1, cb_funcs=cbfs, opt_func=opt_func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMSTtKDgXtjX",
        "colab_type": "code",
        "outputId": "a5cd633b-9ce2-40d8-bde9-8c884ce2f17d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.fit(1, cbs=[LR_Find(), Recorder()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>valid_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, xb, yb)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcb_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_CBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_05b.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09c.py\u001b[0m in \u001b[0;36mafter_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stats\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_train\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_04.py\u001b[0m in \u001b[0;36maccumulate\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtot_mets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_03.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(out, yb)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /pytorch/aten/src/THC/THCTensorMathReduce.cuh:517",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-db4bd680ce9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLR_Find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, cbs, reset_opt)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_begin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, xb, yb)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m:\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09b.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcb_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_CBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_05b.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/exp/nb_09.py\u001b[0m in \u001b[0;36mafter_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot_lr\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    }
  ]
}