{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/stanimman/Pneumonia-Detection/blob/master/Classification_Custom.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YNuzU5fdKxGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ca29c2cc-5ffd-48c3-c656-44ba4a8d2740"
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall Pillow -y\n",
        "\n",
        "!pip install Pillow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-4.0.0:\n",
            "  Successfully uninstalled Pillow-4.0.0\n",
            "Collecting Pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 8.3MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "Successfully installed Pillow-5.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ea5P9V2ELDoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# install dependencies not included by Colab# insta \n",
        "# use pip3 to ensure compatibility w/ Google Deep Learning Images \n",
        "!pip3 install -q pydicom \n",
        "!pip3 install -q tqdm \n",
        "!pip3 install -q imgaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4tIVdbZXLHl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "import sys\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pydicom\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NS2UVvDHLMLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1516
        },
        "outputId": "1370d3f3-d184-44c2-ade6-5854cf5df484"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle-cli\n",
        "!kg download -u 'stanimman' -p '***' -c 'rsna-pneumonia-detection-challenge'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle-cli\n",
            "  Downloading https://files.pythonhosted.org/packages/67/61/710d02460bc4367ffd1f5e71cd9c031fb278f78aa0e8e32ca9dd99a2add8/kaggle-cli-0.12.13.tar.gz\n",
            "Collecting cliff<2.9,>=2.8.0 (from kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/ba/f45621f885ecd8527142811c279740367eb6c552ceb8debfdb7c5fca0677/cliff-2.8.2.tar.gz (72kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 2.5MB/s \n",
            "\u001b[?25hCollecting MechanicalSoup<0.9,>=0.7.0 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2e/f63ed26b51e36efa4cc22cad18187fcb0a253f756d548c96bb931f13de98/MechanicalSoup-0.8.0-py2.py3-none-any.whl\n",
            "Collecting lxml<4.1,>=4.0.0 (from kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/b5/4c6995f8f259f0858f79460e6d277888f8498ce1c1a466dfbb24f06ba83f/lxml-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.3MB 4.1MB/s \n",
            "\u001b[?25hCollecting cssselect<1.1,>=1.0.1 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
            "Collecting configparser (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/69/c2ce7e91c89dc073eb1aa74c0621c3eefbffe8216b3f9af9d3885265c01c/configparser-3.5.0.tar.gz\n",
            "Collecting progressbar2<3.35,>=3.34.3 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/31/b984e17bcc7491c1baeda3906fe3abc14cb5cd5dbd046ab46d9fc7a2edfd/progressbar2-3.34.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4<4.7,>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from kaggle-cli) (4.6.3)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/1c/98cba002ed975a91a0294863d9c774cc0ebe38e05bbb65e83314550b1677/pbr-4.2.0-py2.py3-none-any.whl (100kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 23.9MB/s \n",
            "\u001b[?25hCollecting cmd2>=0.6.7 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/72/8d6638256ae3eea143d94239e98c94d68a8453a226a0cf25a0cc306a7dd5/cmd2-0.9.4-py3-none-any.whl (75kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 19.7MB/s \n",
            "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.1 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (2.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (1.11.0)\n",
            "Collecting stevedore>=1.20.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/d9/93a975469c53a9ee85de9ec0deb12345aa777748b4c263860668592344fe/stevedore-1.29.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (3.13)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2.18.4)\n",
            "Collecting python-utils>=2.1.0 (from progressbar2<3.35,>=3.34.3->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli) (0.1.7)\n",
            "Collecting pyperclip>=1.5.27 (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/9a/23059a00dfd52eb700bd03c4ee3a6954cae60827539c3488026c8742a555/pyperclip-1.6.4.tar.gz\n",
            "Collecting attrs (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/3a/e1/5f9023cc983f1a628a8c2fd051ad19e76ff7b142a0faf329336f9a62a514/attrs-18.2.0-py2.py3-none-any.whl\n",
            "Collecting colorama (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2018.8.24)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (3.0.4)\n",
            "Building wheels for collected packages: kaggle-cli, cliff, configparser, PrettyTable, pyperclip\n",
            "  Running setup.py bdist_wheel for kaggle-cli ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d5/bb/10/c1dd1b08c7433c943cb55c46367ae3f891415e8a37300ff8a7\n",
            "  Running setup.py bdist_wheel for cliff ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/02/22/09/66f8c243f9c68dee7e6456a0fd6c117439a64394fdaf02d965\n",
            "  Running setup.py bdist_wheel for configparser ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a3/61/79/424ef897a2f3b14684a7de5d89e8600b460b89663e6ce9d17c\n",
            "  Running setup.py bdist_wheel for PrettyTable ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Running setup.py bdist_wheel for pyperclip ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/73/8c/77/a973e2fbf4808af077582b1740b4cbf9e100262da0166e90d8\n",
            "Successfully built kaggle-cli cliff configparser PrettyTable pyperclip\n",
            "Installing collected packages: pbr, pyperclip, attrs, colorama, cmd2, PrettyTable, stevedore, cliff, MechanicalSoup, lxml, cssselect, configparser, python-utils, progressbar2, kaggle-cli\n",
            "Successfully installed MechanicalSoup-0.8.0 PrettyTable-0.7.2 attrs-18.2.0 cliff-2.8.2 cmd2-0.9.4 colorama-0.3.9 configparser-3.5.0 cssselect-1.0.3 kaggle-cli-0.12.13 lxml-4.0.0 pbr-4.2.0 progressbar2-3.34.3 pyperclip-1.6.4 python-utils-2.3.0 stevedore-1.29.0\n",
            "/usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py:37: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 37 of the file /usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  response.content, **soup_config)\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/GCP%20Credits%20Request%20Link%20-%20RSNA.txt\n",
            "\n",
            "GCP%20Credits%20Request%20Link%20-%20RSNA.txt 100% |###| Time: 0:00:00 186.8 B/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_detailed_class_info.csv\n",
            "\n",
            "stage_1_detailed_class_info.csv 100% |###############| Time: 0:00:00   2.1 MiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_sample_submission.csv\n",
            "\n",
            "stage_1_sample_submission.csv 100% |#################| Time: 0:00:00 171.3 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_train_labels.csv\n",
            "\n",
            "stage_1_train_labels.csv 100% |######################| Time: 0:00:00   2.1 MiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_test_images.zip\n",
            "\n",
            "stage_1_test_images.zip 100% |#######################| Time: 0:00:05  23.0 MiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_train_images.zip\n",
            "\n",
            "stage_1_train_images.zip 100% |######################| Time: 0:01:48  29.9 MiB/s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KPbIMNR3LUE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "937e664c-014b-4907-fd2d-9bb5d9a40e9b"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/stanimman/Pneumonia-Detection.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Pneumonia-Detection'...\n",
            "remote: Counting objects: 31, done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 31 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (31/31), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F7d-oeKmLnEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip -q -o stage_1_train_images.zip -d stage_1_train_images # Need to understand what is the various argument that is passed on"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Umy3DmGrL3vc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d8fbd045-0175-4064-ecd6-3095eac3130a"
      },
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets.folder import pil_loader\n",
        "from torchvision import transforms, utils\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision import  models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import datetime as dt\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.2.0\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5c488000 @  0x7fe4b7a521c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D5kGeEIaL_Ev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stage_1_train_labels_df = pd.read_csv('Pneumonia-Detection/stage_1_train_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfKiqt6QMEWe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "stage_1_train_labels_df['path'] = stage_1_train_labels_df['patientId']+'.dcm'\n",
        "random_number_list = random.sample(range(0, 28988), 5000)\n",
        "stage_1_test_labels_df = stage_1_train_labels_df.iloc[random_number_list,:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfJ56T7dPzug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Pnumenoia_Case = stage_1_train_labels_df[stage_1_train_labels_df.Target == 1]\n",
        "Non_Pnumenoia_Case = stage_1_train_labels_df[stage_1_train_labels_df.Target == 0]\n",
        "stage_1_train_labels_df = pd.concat([Pnumenoia_Case,(Non_Pnumenoia_Case.iloc[range(10000),:])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ViOqlSafQB9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a09829f0-600c-4dc7-b179-217148bb8570"
      },
      "cell_type": "code",
      "source": [
        "stage_1_train_labels_df.Target.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    10000\n",
              "1     8964\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "-M_332m9QCcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Pnumenoia_Case_test = stage_1_test_labels_df[stage_1_test_labels_df.Target == 1]\n",
        "Non_Pnumenoia_Case_test = stage_1_test_labels_df[stage_1_test_labels_df.Target == 0]\n",
        "stage_1_test_labels_df = pd.concat([Pnumenoia_Case_test.iloc[range(1000),:],Non_Pnumenoia_Case_test.iloc[range(1000),:]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkNRWYOvQkBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6964af20-b32d-497c-e533-e0cfd18be4c3"
      },
      "cell_type": "code",
      "source": [
        "stage_1_test_labels_df.Target.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1000\n",
              "0    1000\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "FrLxE0BYeC3e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Non_Pnumenoia_Case_test = stage_1_test_labels_df[(stage_1_test_labels_df.Target == 0)&(stage_1_test_labels_df.)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWgAfVR1d5GJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "stage_1_test_labels_df = pd.concat([Pnumenoia_Case_test.iloc[range(1000),:],Non_Pnumenoia_Case_test.iloc[range(1000),:]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRKezfLcRKQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RSNADataset(Dataset):\n",
        "    \"\"\"Mura dataset.\"\"\"\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (dataframe): Path to the image file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.df.iloc[idx, 6])\n",
        "        \n",
        "        # Reading Pydicom Files \n",
        "        ds = pydicom.dcmread(img_name)\n",
        "        image = ds.pixel_array\n",
        "        image = np.stack((image,)*3,-1)\n",
        "        labels = self.df.iloc[idx, 5]\n",
        "        labels = labels.astype('float')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return [image, labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDmrwDz7RXX4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transformed_train_dataset = RSNADataset(df=stage_1_train_labels_df,\n",
        "                                    root_dir='stage_1_train_images',\n",
        "                                    transform=transforms.Compose([\n",
        "                                               transforms.ToPILImage(),\n",
        "                                               #transforms.RandomRotation(10),\n",
        "                                               transforms.Resize(224),\n",
        "                                               #transforms.CenterCrop(224),\n",
        "                                               #transforms.RandomHorizontalFlip(),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                               \n",
        "                                           ]))\n",
        "\n",
        "transformed_valid_dataset = RSNADataset(df=stage_1_test_labels_df,\n",
        "                                     root_dir='stage_1_train_images',\n",
        "                                     transform=transforms.Compose([\n",
        "                                                transforms.ToPILImage(),\n",
        "                                                #transforms.RandomRotation(10),\n",
        "                                                transforms.Resize(224),\n",
        "                                                #transforms.CenterCrop(224),\n",
        "                                                #transforms.RandomHorizontalFlip(),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                               \n",
        "                                            ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ArZuSMplR9pE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transformed_train_dl = DataLoader(transformed_train_dataset,batch_size=48,shuffle=True)\n",
        "transformed_valid_dl = DataLoader(transformed_valid_dataset,batch_size=48,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "csQuOmDXSHJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cbe6656-1c2b-481d-b252-2a88c578bced"
      },
      "cell_type": "code",
      "source": [
        "def get_count(layer_name,model_name):\n",
        "  ct  = 0 \n",
        "  layer_count ={}\n",
        "  for name, child in model_name.named_children():\n",
        "      for name2, params in child.named_parameters():\n",
        "        layer_count[name2] = ct\n",
        "        ct +=1\n",
        "  return layer_count[layer_name]\n",
        "\n",
        "def freeze_till(layer_name,model_name):\n",
        "  ct  = 0 \n",
        "  count = get_count(layer_name,model_name)\n",
        "  \n",
        "  for name, child in model_name.named_children():\n",
        "    for name2, params in child.named_parameters():\n",
        "      \n",
        "      if ct > count :\n",
        "          \n",
        "            params.requires_grad = True\n",
        "      else :\n",
        "            params.requires_grad = False\n",
        "      ct +=1\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dataloaders = {\"train\": transformed_train_dl, \"val\": transformed_valid_dl}\n",
        "dataset_sizes = {\"train\": len(transformed_train_dataset),\"val\":len(transformed_valid_dataset)}\n",
        "print(dataset_sizes)\n",
        "\n",
        "## This function evaluate the loss / optimize  and returns model and the weight of the epoch which has highest accuracy\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        # Each epoch has a training and validation phase\n",
        "        # In train phase they are settting 2 variable in model class - train() and schedular  = step()\n",
        "        # In Validation phase setting the model class - eval()\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            # Iterate over data.# phase - train or validation\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                labels = labels.type(torch.cuda.LongTensor)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    \n",
        "                    #print(outputs.shape)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                #print(phase,preds,labels.data)\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            #print(preds[1:10],labels.data[1:10])\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        #print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 18964, 'val': 2000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BdqU_Ep6SLPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0eaf1c94-3eb2-4b4d-baf2-3029c9979197"
      },
      "cell_type": "code",
      "source": [
        "# Load Pretrained model\n",
        "\n",
        "#model_ft = models.resnet18(pretrained=True)\n",
        "model_ft = models.densenet169(pretrained=True)\n",
        "\n",
        "# Freeze specific layers of the model\n",
        "\n",
        "freeze_till('transition2.conv.weight',model_ft)\n",
        "\n",
        "# num_ftrs = model_ft.fc.in_features # fc for resnet\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = torch.tensor([1, 1.05]).type(torch.cuda.FloatTensor))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.torch/models/densenet169-b2777c0a.pth\n",
            "100%|██████████| 57365526/57365526 [00:04<00:00, 12781536.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "E6k-bQrgSPeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "901d07da-a15e-4d0e-dfbf-94e5177169bf"
      },
      "cell_type": "code",
      "source": [
        "optimizer_ft = optim.Adam(list(filter(lambda p: p.requires_grad, model_ft.parameters())), lr = 1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.4272 Acc: 0.8054\n",
            "val Loss: 0.3270 Acc: 0.8665\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.3088 Acc: 0.8677\n",
            "val Loss: 0.2107 Acc: 0.9270\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.1560 Acc: 0.9418\n",
            "val Loss: 0.1544 Acc: 0.9485\n",
            "Epoch 3/9\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-52dd60f41772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 4\u001b[0;31m                        num_epochs=10)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-d94092afb080>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "g-58wpU-dqoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e226acdf-d482-421d-e987-408d897f3086"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GCP%20Credits%20Request%20Link%20-%20RSNA.txt  stage_1_test_images.zip\n",
            "Pneumonia-Detection\t\t\t       stage_1_train_images\n",
            "sample_data\t\t\t\t       stage_1_train_images.zip\n",
            "stage_1_detailed_class_info.csv\t\t       stage_1_train_labels.csv\n",
            "stage_1_sample_submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xp9szF2A5-2l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, num_classes=2):\n",
        "      super(ConvNet, self).__init__()\n",
        "      self.conv1 = nn.Sequential(\n",
        "          nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "          #nn.BatchNorm2d(16),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "      self.conv2 = nn.Sequential(\n",
        "          nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "          #nn.BatchNorm2d(32),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "      self.conv3 = nn.Sequential(\n",
        "              nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "      self.conv4 = nn.Sequential(\n",
        "              nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "      self.conv5 = nn.Sequential(\n",
        "              nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "      self.conv6 = nn.Sequential(\n",
        "              nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "      self.fc1 = nn.Linear(32*32*64, 64)\n",
        "      self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.conv1(x)\n",
        "      out = self.conv2(out)\n",
        "      out = self.conv3(out)\n",
        "      out = self.conv4(out)\n",
        "      out = self.conv5(out)\n",
        "      out = self.conv6(out)\n",
        "      out = out.reshape(out.size(0), -1)\n",
        "      out = self.fc1(out)\n",
        "      out = self.fc2(out)\n",
        "      return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKLeN8zI_DbV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}