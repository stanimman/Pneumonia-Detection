{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/stanimman/Pneumonia-Detection/blob/master/TF_DataSet-recorder_Not_implemented.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "9J7p406abzgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img height=\"60px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"20px\" vspace=\"5px\">\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud. See our [FAQ](https://research.google.com/colaboratory/faq.html) for more info."
      ]
    },
    {
      "metadata": {
        "id": "-Rh3-Vt9Nev9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting Started\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Loading and saving data: Local files, Drive, Sheets, Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Using Google Cloud BigQuery](/notebooks/bigquery.ipynb)\n",
        "- [Forms](/notebooks/forms.ipynb), [Charts](/notebooks/charts.ipynb), [Markdown](/notebooks/markdown_guide.ipynb), & [Widgets](/notebooks/widgets.ipynb)\n",
        "- [TensorFlow with GPU](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPU](/notebooks/tpu.ipynb)\n",
        "- [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/): [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb) & [First Steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n"
      ]
    },
    {
      "metadata": {
        "id": "1fr51oVCHRZU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Highlighted Features\n",
        "### Seedbank\n",
        "\n",
        "Looking for Colab notebooks to learn from? Check out [Seedbank](https://tools.google.com/seedbank/), a place to discover interactive machine learning examples."
      ]
    },
    {
      "metadata": {
        "id": "9wi5kfGdhK0R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TensorFlow execution"
      ]
    },
    {
      "metadata": {
        "id": "S9GW-n-oYWIj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Colaboratory allows you to execute TensorFlow code in your browser with a single click. The example below adds two matrices.\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  1. & 1. & 1. \\\\\n",
        "  1. & 1. & 1. \\\\\n",
        "\\end{bmatrix} +\n",
        "\\begin{bmatrix}\n",
        "  1. & 2. & 3. \\\\\n",
        "  4. & 5. & 6. \\\\\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "  2. & 3. & 4. \\\\\n",
        "  5. & 6. & 7. \\\\\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "metadata": {
        "id": "z1bo30N3D_9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3c37e6ee-1648-4672-f72c-e7549faba0e9"
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall Pillow -y\n",
        "\n",
        "!pip install Pillow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-4.0.0:\n",
            "  Successfully uninstalled Pillow-4.0.0\n",
            "Collecting Pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 12.0MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4xIEPp8aN-f3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "10fb93bf-f501-4e74-97b7-6baced937a90"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle-cli\n",
        "!kg download -u 'stanimman' -p 'Legspinner@1' -c 'rsna-pneumonia-detection-challenge'\n",
        "!git clone https://github.com/stanimman/Pneumonia-Detection.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py:37: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 37 of the file /usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  response.content, **soup_config)\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/GCP%20Credits%20Request%20Link%20-%20RSNA.txt\n",
            "\n",
            "GCP%20Credits%20Request%20Link%20-%20RSNA.txt 100% |###| Time: 0:00:00 120.9 B/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_detailed_class_info.csv\n",
            "\n",
            "stage_1_detailed_class_info.csv 100% |###############| Time: 0:00:00   1.1 MiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_sample_submission.csv\n",
            "\n",
            "stage_1_sample_submission.csv 100% |#################| Time: 0:00:00 113.1 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_train_labels.csv\n",
            "\n",
            "stage_1_train_labels.csv 100% |######################| Time: 0:00:02 240.5 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_test_images.zip\n",
            "\n",
            "stage_1_test_images.zip 100% |#######################| Time: 0:00:04  28.2 MiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/download/stage_1_train_images.zip\n",
            "\n",
            "stage_1_train_images.zip 100% |######################| Time: 0:01:35  34.0 MiB/s\n",
            "\n",
            "Cloning into 'Pneumonia-Detection'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 46 (delta 23), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X7tR7iMtOF7G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip -q -o stage_1_train_images.zip -d stage_1_train_images # Need to understand what is the various argument that is passed on"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v7h7_IJPD3dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "#import knifey"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F3gLU6kzHz_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# install dependencies not included by Colab# insta \n",
        "# use pip3 to ensure compatibility w/ Google Deep Learning Images \n",
        "!pip3 install -q pydicom \n",
        "!pip3 install -q tqdm \n",
        "!pip3 install -q imgaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZsI7l8SLA1C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "import sys\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pydicom\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RiyL_diLIvd1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stage_1_df = pd.read_csv('Pneumonia-Detection/stage_1_train_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yxf5vPkaNgeO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import random\n",
        "stage_1_df['path'] = 'stage_1_train_images/'+stage_1_df['patientId']+'.dcm'\n",
        "#random_number_list = random.sample(range(0, 28988), 5000)\n",
        "#stage_1_test_labels_df = stage_1_train_labels_df.iloc[random_number_list,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gC_0YCdUNuN5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Pnumenoia_Case = stage_1_df[stage_1_df.Target == 1]\n",
        "Non_Pnumenoia_Case = stage_1_df[stage_1_df.Target == 0]\n",
        "stage_1_train_labels_df = pd.concat([Pnumenoia_Case.iloc[range(850),:],(Non_Pnumenoia_Case.iloc[range(1500),:])])\n",
        "stage_1_test_labels_df = pd.concat([Pnumenoia_Case.iloc[851:896,:],(Non_Pnumenoia_Case.iloc[1501:1551,:])])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LYQ-7B_9IPMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "305bf1cb-de3b-42a8-bacb-55254e90ffdf"
      },
      "cell_type": "code",
      "source": [
        "stage_1_train_labels_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patientId</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>Target</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>264.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1</td>\n",
              "      <td>stage_1_train_images/00436515-870c-4b36-a041-d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>562.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>453.0</td>\n",
              "      <td>1</td>\n",
              "      <td>stage_1_train_images/00436515-870c-4b36-a041-d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
              "      <td>323.0</td>\n",
              "      <td>577.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>1</td>\n",
              "      <td>stage_1_train_images/00704310-78a8-4b38-8475-4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
              "      <td>695.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>1</td>\n",
              "      <td>stage_1_train_images/00704310-78a8-4b38-8475-4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>00aecb01-a116-45a2-956c-08d2fa55433f</td>\n",
              "      <td>288.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>1</td>\n",
              "      <td>stage_1_train_images/00aecb01-a116-45a2-956c-0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               patientId      x      y  width  height  Target  \\\n",
              "4   00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1   \n",
              "5   00436515-870c-4b36-a041-de91049b9ab4  562.0  152.0  256.0   453.0       1   \n",
              "8   00704310-78a8-4b38-8475-49f4573b2dbb  323.0  577.0  160.0   104.0       1   \n",
              "9   00704310-78a8-4b38-8475-49f4573b2dbb  695.0  575.0  162.0   137.0       1   \n",
              "14  00aecb01-a116-45a2-956c-08d2fa55433f  288.0  322.0   94.0   135.0       1   \n",
              "\n",
              "                                                 path  \n",
              "4   stage_1_train_images/00436515-870c-4b36-a041-d...  \n",
              "5   stage_1_train_images/00436515-870c-4b36-a041-d...  \n",
              "8   stage_1_train_images/00704310-78a8-4b38-8475-4...  \n",
              "9   stage_1_train_images/00704310-78a8-4b38-8475-4...  \n",
              "14  stage_1_train_images/00aecb01-a116-45a2-956c-0...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "b7h-i9DhIgPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a8fa6561-ba66-4f69-8e11-9056446f4801"
      },
      "cell_type": "code",
      "source": [
        "print(stage_1_train_labels_df.Target.value_counts())\n",
        "print(stage_1_test_labels_df.Target.value_counts())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1500\n",
            "1     850\n",
            "Name: Target, dtype: int64\n",
            "0    50\n",
            "1    45\n",
            "Name: Target, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0m_Wa7x5IoYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abe5cd36-c2ab-408e-b19f-6882c157961b"
      },
      "cell_type": "code",
      "source": [
        "ds = pydicom.dcmread('stage_1_train_images/00436515-870c-4b36-a041-de91049b9ab4.dcm')\n",
        "image = ds.pixel_array\n",
        "image = np.stack((image,)*3,-1)\n",
        "print(image.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1024, 1024, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-3rF7QQlJKfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XCiJO_iuI9xQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ca1326b-ce1a-4075-d555-70a56a384f8c"
      },
      "cell_type": "code",
      "source": [
        "path_tfrecords_train = os.path.join('Pneumonia-Detection', \"train.tfrecords\")\n",
        "path_tfrecords_train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pneumonia-Detection/train.tfrecords'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "hu5o8pwgJO4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "304d5068-8940-48fb-b7d7-2dec9b6a5348"
      },
      "cell_type": "code",
      "source": [
        "path_tfrecords_test = os.path.join('Pneumonia-Detection', \"test.tfrecords\")\n",
        "path_tfrecords_test"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pneumonia-Detection/test.tfrecords'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "YYPnb5GeJaG1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_progress(count, total):\n",
        "    # Percentage completion.\n",
        "    pct_complete = float(count) / total\n",
        "\n",
        "    # Status-message.\n",
        "    # Note the \\r which means the line should overwrite itself.\n",
        "    msg = \"\\r- Progress: {0:.1%}\".format(pct_complete)\n",
        "\n",
        "    # Print it.\n",
        "    sys.stdout.write(msg)\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8Q86_okJeVA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def wrap_int64(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZ72vkkaJiTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def wrap_bytes(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ShKVhzn_MUxS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_paths_train = stage_1_train_labels_df.iloc[:,6].tolist()\n",
        "cls_train = stage_1_train_labels_df.iloc[:,5].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vgbo02fkOf8x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_paths_test = stage_1_test_labels_df.iloc[:,6].tolist()\n",
        "cls_test = stage_1_test_labels_df.iloc[:,5].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYTEAkO9MjWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "738086a3-679f-4f02-a19b-45acb7798328"
      },
      "cell_type": "code",
      "source": [
        "image_paths_test[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stage_1_train_images/1f45c8c0-4475-45e9-85e5-0cf139d0572b.dcm'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "TgIg6WuvJlhv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert(image_paths, labels, out_path):\n",
        "    # Args:\n",
        "    # image_paths   List of file-paths for the images.\n",
        "    # labels        Class-labels for the images.\n",
        "    # out_path      File-path for the TFRecords output file.\n",
        "    \n",
        "    print(\"Converting: \" + out_path)\n",
        "    \n",
        "    # Number of images. Used when printing the progress.\n",
        "    num_images = len(image_paths)\n",
        "    \n",
        "    # Open a TFRecordWriter for the output-file.\n",
        "    with tf.python_io.TFRecordWriter(out_path) as writer:\n",
        "        \n",
        "        # Iterate over all the image-paths and class-labels.\n",
        "        for i, (path, label) in enumerate(zip(image_paths, labels)):\n",
        "            # Print the percentage-progress.\n",
        "            print_progress(count=i, total=num_images-1)\n",
        "\n",
        "            # Load the image-file using matplotlib's imread function.\n",
        "            #img = imread(path)\n",
        "            ds = pydicom.dcmread(path)\n",
        "            img = ds.pixel_array\n",
        "            img = np.stack((img,)*3,-1)\n",
        "            #print(image.shape)\n",
        "            \n",
        "            # Convert the image to raw bytes.\n",
        "            img_bytes = img.tostring()\n",
        "\n",
        "            # Create a dict with the data we want to save in the\n",
        "            # TFRecords file. You can add more relevant data here.\n",
        "            data = \\\n",
        "                {\n",
        "                    'image': wrap_bytes(img_bytes),\n",
        "                    'label': wrap_int64(label)\n",
        "                }\n",
        "\n",
        "            # Wrap the data as TensorFlow Features.\n",
        "            feature = tf.train.Features(feature=data)\n",
        "\n",
        "            # Wrap again as a TensorFlow Example.\n",
        "            example = tf.train.Example(features=feature)\n",
        "\n",
        "            # Serialize the data.\n",
        "            serialized = example.SerializeToString()\n",
        "            \n",
        "            # Write the serialized data to the TFRecords file.\n",
        "            writer.write(serialized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QmQ1AKHJq6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b8f3ae8b-119a-4cb0-e7aa-589a41e22c1b"
      },
      "cell_type": "code",
      "source": [
        "convert(image_paths=image_paths_train,\n",
        "        labels=cls_train,\n",
        "        out_path=path_tfrecords_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting: Pneumonia-Detection/train.tfrecords\n",
            "- Progress: 100.0%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "so0kxHVUJxOO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1ba45cdd-39d5-498b-cc75-d940083afebb"
      },
      "cell_type": "code",
      "source": [
        "convert(image_paths=image_paths_test,\n",
        "        labels=cls_test,\n",
        "        out_path=path_tfrecords_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting: Pneumonia-Detection/test.tfrecords\n",
            "- Progress: 100.0%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T_cTbkNTHrwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "644ff800-af09-4caf-952a-d6ae412b75ba"
      },
      "cell_type": "code",
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "TPU_WORKER"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grpc://10.55.187.10:8470'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "nripuT3jFMpr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu = TPU_WORKER\n",
        "gcp_project = 'tpu_exp'\n",
        "batch_size = 128\n",
        "learning_rate = 0.05\n",
        "train_steps = 100000\n",
        "use_tpu = True\n",
        "model_dir = 'MyDir'\n",
        "iterations_per_loop = 100\n",
        "num_shards = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4gdnpN2Fzlw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_fn(features, labels, mode, params):\n",
        "  \"\"\"Define a CIFAR model in Keras.\"\"\"\n",
        "  del params  # unused\n",
        "  layers = tf.contrib.keras.layers\n",
        "\n",
        "  # Pass our input tensor to initialize the Keras input layer.\n",
        "  v = layers.Input(tensor=features)\n",
        "  v = layers.Conv2D(filters=32, kernel_size=5,\n",
        "                    activation=\"relu\", padding=\"same\")(v)\n",
        "  v = layers.MaxPool2D(pool_size=2)(v)\n",
        "  v = layers.Conv2D(filters=64, kernel_size=5,\n",
        "                    activation=\"relu\", padding=\"same\")(v)\n",
        "  v = layers.MaxPool2D(pool_size=2)(v)\n",
        "  v = layers.Flatten()(v)\n",
        "  fc1 = layers.Dense(units=512, activation=\"relu\")(v)\n",
        "  logits = layers.Dense(units=2)(fc1)\n",
        "\n",
        "  # Instead of constructing a Keras model for training, build our loss function\n",
        "  # and optimizer in Tensorflow.\n",
        "  #\n",
        "  # N.B.  This construction omits some features that are important for more\n",
        "  # complex models (e.g. regularization, batch-norm).  Once\n",
        "  # `model_to_estimator` support is added for TPUs, it should be used instead.\n",
        "  loss = tf.reduce_mean(\n",
        "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          logits=logits, labels=labels\n",
        "      )\n",
        "  )\n",
        "  optimizer = tf.train.AdamOptimizer()\n",
        "  if use_tpu:\n",
        "    optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "\n",
        "  train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
        "\n",
        "  return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "      mode=mode,\n",
        "      loss=loss,\n",
        "      train_op=train_op,\n",
        "      predictions={\n",
        "          \"classes\": tf.argmax(input=logits, axis=1),\n",
        "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "      }\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M3gPzqwrGJub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn(params):\n",
        "  \"\"\"Read CIFAR input data from a TFRecord dataset.\"\"\"\n",
        "  del params\n",
        "  batch_size = 128\n",
        "  train_file = 'Pneumonia-Detection/train.tfrecords'\n",
        "  def parser(serialized_example):\n",
        "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
        "    features = tf.parse_single_example(\n",
        "        serialized_example,\n",
        "        features={\n",
        "            \"image\": tf.FixedLenFeature([], tf.string),\n",
        "            \"label\": tf.FixedLenFeature([], tf.int64),\n",
        "        })\n",
        "    image = tf.decode_raw(features[\"image\"], tf.uint8)\n",
        "    image.set_shape([3*32*32])\n",
        "    image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n",
        "    image = tf.transpose(tf.reshape(image, [3, 32, 32]))\n",
        "    label = tf.cast(features[\"label\"], tf.int32)\n",
        "    return image, label\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset([train_file])\n",
        "  dataset = dataset.map(parser, num_parallel_calls=batch_size)\n",
        "  dataset = dataset.prefetch(4 * batch_size).cache().repeat()\n",
        "  dataset = dataset.apply(\n",
        "      tf.contrib.data.batch_and_drop_remainder(batch_size)\n",
        "  )\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uxFVQG7HAcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "      tpu,\n",
        "      project= gcp_project)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      #model_dir = '/Pneumonia-Detection',\n",
        "      save_checkpoints_secs=3600,\n",
        "      session_config=tf.ConfigProto(\n",
        "          allow_soft_placement=True, log_device_placement=True),\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=iterations_per_loop,\n",
        "          num_shards=num_shards),\n",
        "  )\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1vFciGKHHXyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "232ccde4-1a54-4ab4-d026-046ceebff57c"
      },
      "cell_type": "code",
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      model_fn=model_fn,\n",
        "      use_tpu= use_tpu,\n",
        "      config=run_config,\n",
        "      train_batch_size= batch_size)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f8ac98b0d90>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmzvm3lgs\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpmzvm3lgs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 3600, '_session_config': allow_soft_placement: true\n",
            "log_device_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.55.187.10:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8ac80174a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.55.187.10:8470', '_evaluation_master': b'grpc://10.55.187.10:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7f8ac75887b8>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W4mu3uKzIC7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6865
        },
        "outputId": "014607bf-21f8-42fc-9cce-acb20f8c0965"
      },
      "cell_type": "code",
      "source": [
        "estimator.train(input_fn=input_fn, max_steps=train_steps)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.55.187.10:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 656491828873089236)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16143568905366491705)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 9000698506957066683)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10801824659740258392)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 9464786048293367700)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5712284084077381697)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14779217345875107861)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15381486979646337979)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7177679748932854742)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14803137419745746453)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1258619312967802871)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 11845372994905382378)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpmzvm3lgs/model.ckpt.\n",
            "INFO:tensorflow:Error recorded from training_loop: File system scheme '[local]' not implemented (file: '/tmp/tmpmzvm3lgs/model.ckpt-0_temp_2584fa579f0b4b5d84bdf95df4377de6')\n",
            "\t [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power/Read/ReadVariableOp, beta2_power/Read/ReadVariableOp, conv2d/bias/Read/ReadVariableOp, conv2d/bias/Adam/Read_1/ReadVariableOp, conv2d/bias/Adam_1/Read_1/ReadVariableOp, conv2d/kernel/Read/ReadVariableOp, conv2d/kernel/Adam/Read_1/ReadVariableOp, conv2d/kernel/Adam_1/Read_1/ReadVariableOp, conv2d_1/bias/Read/ReadVariableOp, conv2d_1/bias/Adam/Read_1/ReadVariableOp, conv2d_1/bias/Adam_1/Read_1/ReadVariableOp, conv2d_1/kernel/Read/ReadVariableOp, conv2d_1/kernel/Adam/Read_1/ReadVariableOp, conv2d_1/kernel/Adam_1/Read_1/ReadVariableOp, dense/bias/Read/ReadVariableOp, dense/bias/Adam/Read_1/ReadVariableOp, dense/bias/Adam_1/Read_1/ReadVariableOp, dense/kernel/Read/ReadVariableOp, dense/kernel/Adam/Read_1/ReadVariableOp, dense/kernel/Adam_1/Read_1/ReadVariableOp, dense_1/bias/Read/ReadVariableOp, dense_1/bias/Adam/Read_1/ReadVariableOp, dense_1/bias/Adam_1/Read_1/ReadVariableOp, dense_1/kernel/Read/ReadVariableOp, dense_1/kernel/Adam/Read_1/ReadVariableOp, dense_1/kernel/Adam_1/Read_1/ReadVariableOp, global_step/Read/ReadVariableOp)]]\n",
            "\n",
            "Caused by op 'save/SaveV2', defined at:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
            "    ioloop.IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
            "    super(ZMQIOLoop, self).start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n",
            "    handler_func(fd_obj, events)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-45-fb47a8605fbf>\", line 1, in <module>\n",
            "    estimator.train(input_fn=input_fn, max_steps=train_steps)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2394, in train\n",
            "    saving_listeners=saving_listeners\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 356, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1181, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1215, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1406, in _train_with_estimator_spec\n",
            "    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 504, in MonitoredTrainingSession\n",
            "    stop_grace_period_secs=stop_grace_period_secs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 921, in __init__\n",
            "    stop_grace_period_secs=stop_grace_period_secs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 643, in __init__\n",
            "    self._sess = _RecoverableSession(self._coordinated_creator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1107, in __init__\n",
            "    _WrappedSession.__init__(self, self._create_session())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1112, in _create_session\n",
            "    return self._sess_creator.create_session()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 800, in create_session\n",
            "    self.tf_sess = self._session_creator.create_session()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 557, in create_session\n",
            "    self._scaffold.finalize()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 215, in finalize\n",
            "    self._saver.build()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1106, in build\n",
            "    self._build(self._filename, build_save=True, build_restore=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1143, in _build\n",
            "    build_save=build_save, build_restore=build_restore)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n",
            "    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 369, in _AddShardedSaveOps\n",
            "    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 343, in _AddShardedSaveOpsForV2\n",
            "    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 284, in _AddSaveOps\n",
            "    save = self.save_op(filename_tensor, saveables)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 202, in save_op\n",
            "    tensors)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1690, in save_v2\n",
            "    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "UnimplementedError (see above for traceback): File system scheme '[local]' not implemented (file: '/tmp/tmpmzvm3lgs/model.ckpt-0_temp_2584fa579f0b4b5d84bdf95df4377de6')\n",
            "\t [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power/Read/ReadVariableOp, beta2_power/Read/ReadVariableOp, conv2d/bias/Read/ReadVariableOp, conv2d/bias/Adam/Read_1/ReadVariableOp, conv2d/bias/Adam_1/Read_1/ReadVariableOp, conv2d/kernel/Read/ReadVariableOp, conv2d/kernel/Adam/Read_1/ReadVariableOp, conv2d/kernel/Adam_1/Read_1/ReadVariableOp, conv2d_1/bias/Read/ReadVariableOp, conv2d_1/bias/Adam/Read_1/ReadVariableOp, conv2d_1/bias/Adam_1/Read_1/ReadVariableOp, conv2d_1/kernel/Read/ReadVariableOp, conv2d_1/kernel/Adam/Read_1/ReadVariableOp, conv2d_1/kernel/Adam_1/Read_1/ReadVariableOp, dense/bias/Read/ReadVariableOp, dense/bias/Adam/Read_1/ReadVariableOp, dense/bias/Adam_1/Read_1/ReadVariableOp, dense/kernel/Read/ReadVariableOp, dense/kernel/Adam/Read_1/ReadVariableOp, dense/kernel/Adam_1/Read_1/ReadVariableOp, dense_1/bias/Read/ReadVariableOp, dense_1/bias/Adam/Read_1/ReadVariableOp, dense_1/bias/Adam_1/Read_1/ReadVariableOp, dense_1/kernel/Read/ReadVariableOp, dense_1/kernel/Adam/Read_1/ReadVariableOp, dense_1/kernel/Adam_1/Read_1/ReadVariableOp, global_step/Read/ReadVariableOp)]]\n",
            "\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "WARNING:tensorflow:Reraising captured error\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: '/tmp/tmpmzvm3lgs/model.ckpt-0_temp_2584fa579f0b4b5d84bdf95df4377de6')\n\t [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power/Read/ReadVariableOp, beta2_power/Read/ReadVariableOp, conv2d/bias/Read/ReadVariableOp, conv2d/bias/Adam/Read_1/ReadVariableOp, conv2d/bias/Adam_1/Read_1/ReadVariableOp, conv2d/kernel/Read/ReadVariableOp, conv2d/kernel/Adam/Read_1/ReadVariableOp, conv2d/kernel/Adam_1/Read_1/ReadVariableOp, conv2d_1/bias/Read/ReadVariableOp, conv2d_1/bias/Adam/Read_1/ReadVariableOp, conv2d_1/bias/Adam_1/Read_1/ReadVariableOp, conv2d_1/kernel/Read/ReadVariableOp, conv2d_1/kernel/Adam/Read_1/ReadVariableOp, conv2d_1/kernel/Adam_1/Read_1/ReadVariableOp, dense/bias/Read/ReadVariableOp, dense/bias/Adam/Read_1/ReadVariableOp, dense/bias/Adam_1/Read_1/ReadVariableOp, dense/kernel/Read/ReadVariableOp, dense/kernel/Adam/Read_1/ReadVariableOp, dense/kernel/Adam_1/Read_1/ReadVariableOp, dense_1/bias/Read/ReadVariableOp, dense_1/bias/Adam/Read_1/ReadVariableOp, dense_1/bias/Adam_1/Read_1/ReadVariableOp, dense_1/kernel/Read/ReadVariableOp, dense_1/kernel/Adam/Read_1/ReadVariableOp, dense_1/kernel/Adam_1/Read_1/ReadVariableOp, global_step/Read/ReadVariableOp)]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-fb47a8605fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   2398\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2400\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m   def evaluate(self, input_fn, steps=None, hooks=None, checkpoint_path=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   2392\u001b[0m       return super(TPUEstimator, self).train(\n\u001b[1;32m   2393\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2394\u001b[0;31m           \u001b[0msaving_listeners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2395\u001b[0m       )\n\u001b[1;32m   2396\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1214\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m   1407\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    920\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \"\"\"\n\u001b[1;32m   1106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# Inform the hooks that a new session has been created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m       return _CoordinatedSession(\n\u001b[1;32m    809\u001b[0m           \u001b[0m_HookedSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36mafter_create_session\u001b[0;34m(self, session, coord)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;31m# The checkpoint saved here is the state at step \"global_step\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_last_triggered_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, session, step)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     self._summary_writer.add_session_log(\n\u001b[1;32m    600\u001b[0m         SessionLog(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1431\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1432\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: '/tmp/tmpmzvm3lgs/model.ckpt-0_temp_2584fa579f0b4b5d84bdf95df4377de6')\n\t [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power/Read/ReadVariableOp, beta2_power/Read/ReadVariableOp, conv2d/bias/Read/ReadVariableOp, conv2d/bias/Adam/Read_1/ReadVariableOp, conv2d/bias/Adam_1/Read_1/ReadVariableOp, conv2d/kernel/Read/ReadVariableOp, conv2d/kernel/Adam/Read_1/ReadVariableOp, conv2d/kernel/Adam_1/Read_1/ReadVariableOp, conv2d_1/bias/Read/ReadVariableOp, conv2d_1/bias/Adam/Read_1/ReadVariableOp, conv2d_1/bias/Adam_1/Read_1/ReadVariableOp, conv2d_1/kernel/Read/ReadVariableOp, conv2d_1/kernel/Adam/Read_1/ReadVariableOp, conv2d_1/kernel/Adam_1/Read_1/ReadVariableOp, dense/bias/Read/ReadVariableOp, dense/bias/Adam/Read_1/ReadVariableOp, dense/bias/Adam_1/Read_1/ReadVariableOp, dense/kernel/Read/ReadVariableOp, dense/kernel/Adam/Read_1/ReadVariableOp, dense/kernel/Adam_1/Read_1/ReadVariableOp, dense_1/bias/Read/ReadVariableOp, dense_1/bias/Adam/Read_1/ReadVariableOp, dense_1/bias/Adam_1/Read_1/ReadVariableOp, dense_1/kernel/Read/ReadVariableOp, dense_1/kernel/Adam/Read_1/ReadVariableOp, dense_1/kernel/Adam_1/Read_1/ReadVariableOp, global_step/Read/ReadVariableOp)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-45-fb47a8605fbf>\", line 1, in <module>\n    estimator.train(input_fn=input_fn, max_steps=train_steps)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2394, in train\n    saving_listeners=saving_listeners\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 356, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1181, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1215, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1406, in _train_with_estimator_spec\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 504, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 921, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 643, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1107, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1112, in _create_session\n    return self._sess_creator.create_session()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 800, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 557, in create_session\n    self._scaffold.finalize()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 215, in finalize\n    self._saver.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1106, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1143, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 369, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 343, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 284, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 202, in save_op\n    tensors)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1690, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnimplementedError (see above for traceback): File system scheme '[local]' not implemented (file: '/tmp/tmpmzvm3lgs/model.ckpt-0_temp_2584fa579f0b4b5d84bdf95df4377de6')\n\t [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power/Read/ReadVariableOp, beta2_power/Read/ReadVariableOp, conv2d/bias/Read/ReadVariableOp, conv2d/bias/Adam/Read_1/ReadVariableOp, conv2d/bias/Adam_1/Read_1/ReadVariableOp, conv2d/kernel/Read/ReadVariableOp, conv2d/kernel/Adam/Read_1/ReadVariableOp, conv2d/kernel/Adam_1/Read_1/ReadVariableOp, conv2d_1/bias/Read/ReadVariableOp, conv2d_1/bias/Adam/Read_1/ReadVariableOp, conv2d_1/bias/Adam_1/Read_1/ReadVariableOp, conv2d_1/kernel/Read/ReadVariableOp, conv2d_1/kernel/Adam/Read_1/ReadVariableOp, conv2d_1/kernel/Adam_1/Read_1/ReadVariableOp, dense/bias/Read/ReadVariableOp, dense/bias/Adam/Read_1/ReadVariableOp, dense/bias/Adam_1/Read_1/ReadVariableOp, dense/kernel/Read/ReadVariableOp, dense/kernel/Adam/Read_1/ReadVariableOp, dense/kernel/Adam_1/Read_1/ReadVariableOp, dense_1/bias/Read/ReadVariableOp, dense_1/bias/Adam/Read_1/ReadVariableOp, dense_1/bias/Adam_1/Read_1/ReadVariableOp, dense_1/kernel/Read/ReadVariableOp, dense_1/kernel/Adam/Read_1/ReadVariableOp, dense_1/kernel/Adam_1/Read_1/ReadVariableOp, global_step/Read/ReadVariableOp)]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6l1rSWpjPCY_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cloud TPU Cluster Resolvers\n",
        "flags.DEFINE_string(\n",
        "    'tpu', 'grpc://10.23.169.218:8470',\n",
        "    help='The Cloud TPU to use for training. This should be either the name '\n",
        "    'used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 url.')\n",
        "flags.DEFINE_string(\n",
        "    \"gcp_project\", 'tpu_exp',\n",
        "    help=\"Project name for the Cloud TPU-enabled project. If not specified, we \"\n",
        "    \"will attempt to automatically detect the GCE project from metadata.\")\n",
        "flags.DEFINE_string(\n",
        "    \"tpu_zone\", default=None,\n",
        "    help=\"GCE zone where the Cloud TPU is located in. If not specified, we \"\n",
        "    \"will attempt to automatically detect the GCE project from metadata.\")\n",
        "\n",
        "# Model specific paramenters\n",
        "flags.DEFINE_integer(\"batch_size\", 128,\n",
        "                     \"Mini-batch size for the computation. Note that this \"\n",
        "                     \"is the global batch size and not the per-shard batch.\")\n",
        "flags.DEFINE_float(\"learning_rate\", 0.05, \"Learning rate.\")\n",
        "flags.DEFINE_string(\"train_file\", \"XR_FOREARM/train.tfrecords\", \"Path to cifar10 training data.\")\n",
        "flags.DEFINE_integer(\"train_steps\", 100000,\n",
        "                     \"Total number of steps. Note that the actual number of \"\n",
        "                     \"steps is the next multiple of --iterations greater \"\n",
        "                     \"than this value.\")\n",
        "flags.DEFINE_bool(\"use_tpu\", True, \"Use TPUs rather than plain CPUs\")\n",
        "flags.DEFINE_string(\"model_dir\", 'XR_FOREARM', \"Estimator model_dir\")\n",
        "flags.DEFINE_string(\"logtostderr\", 'Warning', \"Estimator model_dir\")\n",
        "flags.DEFINE_integer(\"iterations_per_loop\", 100,\n",
        "                     \"Number of iterations per TPU training loop.\")\n",
        "flags.DEFINE_integer(\"num_shards\", 8, \"Number of shards (TPU chips).\")\n",
        "\n",
        "\n",
        "FLAGS = flags.FLAGS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CCmHWuMoQfSH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn(filenames,params,train, batch_size=32, buffer_size=2048):\n",
        "    # Args:\n",
        "    # filenames:   Filenames for the TFRecords files.\n",
        "    # train:       Boolean whether training (True) or testing (False).\n",
        "    # batch_size:  Return batches of this size.\n",
        "    # buffer_size: Read buffers of this size. The random shuffling\n",
        "    #              is done on the buffer, so it must be big enough.\n",
        "\n",
        "    # Create a TensorFlow Dataset-object which has functionality\n",
        "    # for reading and shuffling data from TFRecords files.\n",
        "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
        "\n",
        "    # Parse the serialized data in the TFRecords files.\n",
        "    # This returns TensorFlow tensors for the image and labels.\n",
        "    dataset = dataset.map(parse)\n",
        "\n",
        "    if train:\n",
        "        # If training then read a buffer of the given size and\n",
        "        # randomly shuffle it.\n",
        "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
        "\n",
        "        # Allow infinite reading of the data.\n",
        "        num_repeat = None\n",
        "    else:\n",
        "        # If testing then don't shuffle the data.\n",
        "        \n",
        "        # Only go through the data once.\n",
        "        num_repeat = 1\n",
        "\n",
        "    # Repeat the dataset the given number of times.\n",
        "    dataset = dataset.repeat(num_repeat)\n",
        "    \n",
        "    # Get a batch of data with the given size.\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Create an iterator for the dataset and the above modifications.\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "    # Get the next batch of images and labels.\n",
        "    images_batch, labels_batch = iterator.get_next()\n",
        "\n",
        "    # The input-function must return a dict wrapping the images.\n",
        "    x = {'image': images_batch}\n",
        "    y = labels_batch\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2M4arPeQrY7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn():\n",
        "    return input_fn(filenames=path_tfrecords_train, train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DfmQvuGEWwXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "919965f8-57ba-4c10-e1a4-35872b18c008"
      },
      "cell_type": "code",
      "source": [
        "path_tfrecords_train"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'XR_FOREARM/train.tfrecords'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "NbAy6fcRQr-v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_input_fn():\n",
        "    return input_fn(filenames=path_tfrecords_test, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7kbN9jTTRzYo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_images(image_paths):\n",
        "    # Load the images from disk.\n",
        "    #images = [imread(path) for path in image_paths]\n",
        "    for path in image_paths:\n",
        "      ds = pydicom.dcmread(path)\n",
        "      images = ds.pixel_array\n",
        "      images = np.stack((images,)*3,-1)\n",
        "\n",
        "    # Convert to a numpy array and return it.\n",
        "    return np.asarray(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rol1Psq5Qwj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "some_images = load_images(image_paths=image_paths_test[0:9])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UOcoxFm2SCAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"image\": some_images.astype(np.float32)},\n",
        "    num_epochs=1,\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyPQtgxyUE2K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "some_images_cls = cls_test[0:9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sTstQorJycm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a42e06f-f353-449a-c477-7109410d858b"
      },
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024, 1024, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "lroPBDk-AnPL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_image = tf.feature_column.numeric_column(\"image\",\n",
        "                                                 shape=image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDLtAO4cA2DB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_columns = [feature_image]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yhcJalHZA4_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_hidden_units = [512, 256, 128]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NY1PTXejFtgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a4c7fb2b-e5f3-4097-9eb9-91823ac0043e"
      },
      "cell_type": "code",
      "source": [
        "model = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
        "                                   hidden_units=num_hidden_units,\n",
        "                                   activation_fn=tf.nn.relu,\n",
        "                                   n_classes=2,\n",
        "                                   model_dir=\"XR_FOREARM/New\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'XR_FOREARM/New', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7ea2353908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y4XtaJC-F9xr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "8f152ee9-55b9-47da-acc1-ddc56946896c"
      },
      "cell_type": "code",
      "source": [
        "model.train(input_fn=train_input_fn, steps=20)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-651ccbb92857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Hfiy-vMuNjug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "ded960c0-e038-4b27-bf73-60b593118696"
      },
      "cell_type": "code",
      "source": [
        "result = model.evaluate(input_fn=test_input_fn)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b6db7181bf2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Xd87zvlIBaX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30d7297c-c728-48b7-c020-bfb79a40d5cc"
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall flags -y"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mSkipping flags as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gpYQE3cPCTEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_fn(features, labels, mode, params):\n",
        "    # Args:\n",
        "    #\n",
        "    # features: This is the x-arg from the input_fn.\n",
        "    # labels:   This is the y-arg from the input_fn.\n",
        "    # mode:     Either TRAIN, EVAL, or PREDICT\n",
        "    # params:   User-defined hyper-parameters, e.g. learning-rate.\n",
        "    \n",
        "    # Reference to the tensor named \"image\" in the input-function.\n",
        "    x = features[\"image\"]\n",
        "\n",
        "    # The convolutional layers expect 4-rank tensors\n",
        "    # but x is a 2-rank tensor, so reshape it.\n",
        "    net = tf.reshape(x, [-1, img_size, img_size, num_channels])    \n",
        "\n",
        "    # First convolutional layer.\n",
        "    net = tf.layers.conv2d(inputs=net, name='layer_conv1',\n",
        "                           filters=32, kernel_size=3,\n",
        "                           padding='same', activation=tf.nn.relu)\n",
        "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
        "\n",
        "    # Second convolutional layer.\n",
        "    net = tf.layers.conv2d(inputs=net, name='layer_conv2',\n",
        "                           filters=32, kernel_size=3,\n",
        "                           padding='same', activation=tf.nn.relu)\n",
        "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)    \n",
        "\n",
        "    # Flatten to a 2-rank tensor.\n",
        "    net = tf.contrib.layers.flatten(net)\n",
        "    # Eventually this should be replaced with:\n",
        "    # net = tf.layers.flatten(net)\n",
        "\n",
        "    # First fully-connected / dense layer.\n",
        "    # This uses the ReLU activation function.\n",
        "    net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
        "                          units=128, activation=tf.nn.relu)    \n",
        "\n",
        "    # Second fully-connected / dense layer.\n",
        "    # This is the last layer so it does not use an activation function.\n",
        "    net = tf.layers.dense(inputs=net, name='layer_fc_2',\n",
        "                          units=2)\n",
        "\n",
        "    # Logits output of the neural network.\n",
        "    logits = net\n",
        "\n",
        "    # Softmax output of the neural network.\n",
        "    y_pred = tf.nn.softmax(logits=logits)\n",
        "    \n",
        "    # Classification output of the neural network.\n",
        "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        # If the estimator is supposed to be in prediction-mode\n",
        "        # then use the predicted class-number that is output by\n",
        "        # the neural network. Optimization etc. is not needed.\n",
        "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                          predictions=y_pred_cls)\n",
        "    else:\n",
        "        # Otherwise the estimator is supposed to be in either\n",
        "        # training or evaluation-mode. Note that the loss-function\n",
        "        # is also required in Evaluation mode.\n",
        "        \n",
        "        # Define the loss-function to be optimized, by first\n",
        "        # calculating the cross-entropy between the output of\n",
        "        # the neural network and the true labels for the input data.\n",
        "        # This gives the cross-entropy for each image in the batch.\n",
        "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
        "                                                                       logits=logits)\n",
        "\n",
        "        # Reduce the cross-entropy batch-tensor to a single number\n",
        "        # which can be used in optimization of the neural network.\n",
        "        loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "        # Define the optimizer for improving the neural network.\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
        "\n",
        "        # Get the TensorFlow op for doing a single optimization step.\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss, global_step=tf.train.get_global_step())\n",
        "\n",
        "        # Define the evaluation metrics,\n",
        "        # in this case the classification accuracy.\n",
        "        metrics = \\\n",
        "        {\n",
        "            \"accuracy\": tf.metrics.accuracy(labels, y_pred_cls)\n",
        "        }\n",
        "\n",
        "        # Wrap all of this in an EstimatorSpec.\n",
        "        spec = tf.estimator.EstimatorSpec(\n",
        "            mode=mode,\n",
        "            loss=loss,\n",
        "            train_op=train_op,\n",
        "            eval_metric_ops=metrics)\n",
        "        \n",
        "    return spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2m3rmkS_DBWH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = {\"learning_rate\": 1e-4}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0YXDCq0DEQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "cb709c74-3b6d-4aa2-b0ab-f14a13af023f"
      },
      "cell_type": "code",
      "source": [
        "model = tf.estimator.Estimator(model_fn=model_fn,\n",
        "                               params=params,\n",
        "                               use_tpu=True,\n",
        "                               model_dir=\"XR_FOREARM/New\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5564563e0821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                                \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                \u001b[0muse_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                model_dir=\"XR_FOREARM/New\")\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'use_tpu'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Kb2br9TNRnrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6a7ccdf-9b42-417e-bfb9-a6b38396bce8"
      },
      "cell_type": "code",
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "TPU_WORKER"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grpc://10.71.10.34:8470'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "g9bxs0KXRZn9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "      'grpc://10.71.10.34:8470'\n",
        "      )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qllxv1sRROle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      model_dir=\"XR_FOREARM/New\",\n",
        "      save_checkpoints_secs=3600,\n",
        "      session_config=tf.ConfigProto(\n",
        "          allow_soft_placement=True, log_device_placement=True),\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=100,\n",
        "          num_shards=8),\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5kriYobRFKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2445
        },
        "outputId": "37109ee6-9747-4a30-81b4-2112a63043e1"
      },
      "cell_type": "code",
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      model_fn=model_fn,\n",
        "      params=params,\n",
        "      use_tpu=True,\n",
        "      config=run_config,\n",
        "      train_batch_size=128)\n",
        "estimator.train(input_fn=input_fn, max_steps=100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'XR_FOREARM/New', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 3600, '_session_config': allow_soft_placement: true\n",
            "log_device_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.71.10.34:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe8357b02b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.71.10.34:8470', '_evaluation_master': b'grpc://10.71.10.34:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe83b851588>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.71.10.34:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 14167402108873847339)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6213812686446419214)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 18265712071882679437)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3259713194115967179)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 8994260091991241248)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8482710280708210966)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9771431414202814090)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13411502929818504194)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 17185853115987787275)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10994784468524234332)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2993720475172172304)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 18438939768627589582)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Error recorded from training_loop: input_fn() missing 2 required positional arguments: 'filenames' and 'train'\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "WARNING:tensorflow:Reraising captured error\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9344072324f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       train_batch_size=128)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   2398\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2400\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m   def evaluate(self, input_fn, steps=None, hooks=None, checkpoint_path=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   2392\u001b[0m       return super(TPUEstimator, self).train(\n\u001b[1;32m   2393\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2394\u001b[0;31m           \u001b[0msaving_listeners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2395\u001b[0m       )\n\u001b[1;32m   2396\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1211\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1212\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   2184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m       return super(TPUEstimator, self)._call_model_fn(\n\u001b[0;32m-> 2186\u001b[0;31m           features, labels, mode, config)\n\u001b[0m\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn_for_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config, params)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0minput_holders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_InputPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         enqueue_ops, dequeue_fn, input_hooks, run_infeed_loop_on_coordinator = (\n\u001b[0;32m-> 2482\u001b[0;31m             input_holders.generate_infeed_enqueue_ops_and_dequeue_fn())\n\u001b[0m\u001b[1;32m   2483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mgenerate_infeed_enqueue_ops_and_dequeue_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0;31m# structure is recorded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     enqueue_ops, all_hooks, run_infeed_loop_on_coordinator = (\n\u001b[0;32m-> 1096\u001b[0;31m         self._invoke_input_fn_and_record_structure())\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_invoke_input_fn_and_record_structure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs_structure_recorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                       host_device, host_id))\n\u001b[0m\u001b[1;32m   1179\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mgenerate_per_host_enqueue_ops_fn_for_host\u001b[0;34m(ctx, input_fn, inputs_structure_recorder, batch_axis, device, host_id)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0minput_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         invocation_index=host_id)\n\u001b[0;32m--> 684\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0mis_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_input_fn\u001b[0;34m(ctx)\u001b[0m\n\u001b[1;32m   2366\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m         \u001b[0m_add_item_to_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_CTX_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_input_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: input_fn() missing 2 required positional arguments: 'filenames' and 'train'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OeTCEQ0sQkZP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKOwNshXS2F5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59cc2253-4abf-42f6-b788-403caf737d32"
      },
      "cell_type": "code",
      "source": [
        "isinstance(some_images, (np.ndarray))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "nwYF0E3Sjiy4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GitHub\n",
        "\n",
        "You can save a copy of your Colab notebook to Github by using File > Save a copy to GitHub…\n",
        "\n",
        "You can load any .ipynb on GitHub by just adding the path to colab.research.google.com/github/ . For example, [colab.research.google.com/github/tensorflow/models/blob/master/samples/core/get_started/_index.ipynb](https://colab.research.google.com/github/tensorflow/models/blob/master/samples/core/get_started/_index.ipynb) will load [this .ipynb](https://github.com/tensorflow/models/blob/master/samples/core/get_started/_index.ipynb) on GitHub.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yv2XIwi5hQ_g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ]
    },
    {
      "metadata": {
        "id": "rYs5mx2JZkmy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Colaboratory includes widely used libraries like [matplotlib](https://matplotlib.org/), simplifying visualization."
      ]
    },
    {
      "metadata": {
        "id": "xqrc5C-IaA5J",
        "colab_type": "code",
        "colab": {
          "height": 360
        },
        "outputId": "3460cc84-faf8-4d8c-a4e6-96a6809c389a"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.arange(20)\n",
        "y = [x_i + np.random.randn(1) for x_i in x]\n",
        "a, b = np.polyfit(x, y, 1)\n",
        "_ = plt.plot(x, y, 'o', np.arange(20), a*np.arange(20)+b, '-')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFXCAYAAABpzN2sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x562d64cf1b10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "AN_LRQ9NkOjs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Want to use a new library?  `pip install` it at the top of the notebook. Then that library can be used anywhere else in the notebook. For recipes to import commonly used libraries, refer to the [importing libraries example notebook](/notebooks/snippets/importing_libraries.ipynb)."
      ]
    },
    {
      "metadata": {
        "id": "FlQq0SUepQbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "6e404831-3336-4633-b76f-c6313ecdd356"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q matplotlib-venn\n",
        "\n",
        "from matplotlib_venn import venn2\n",
        "_ = venn2(subsets = (3, 2, 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAE5CAYAAAAeMx4EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxIiISFn/H6CFJPx9gio9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f48ff99ff10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LxZ3dPzYnyNF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Forms\n",
        "\n",
        "Forms can be used to parameterize code. See the [forms example notebook](/notebooks/forms.ipynb) for more details."
      ]
    },
    {
      "metadata": {
        "id": "FQ_Hx_9tn7uF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Examples\n",
        "\n",
        "text = 'value' #@param \n",
        "date_input = '2018-03-22' #@param {type:\"date\"}\n",
        "number_slider = 0 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "dropdown = '1st option' #@param [\"1st option\", \"2nd option\", \"3rd option\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTX3heEtu0b2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Local runtime support\n",
        "\n",
        "Colab  supports connecting to a Jupyter runtime on your local machine. For more information, see our [documentation](https://research.google.com/colaboratory/local-runtimes.html)."
      ]
    }
  ]
}